={basic} 기본 지식
성능 튜닝을 할 때는 애플리케이션 전체를 조사하고 수정해야 한다. 
따라서 효과적인 성능 튜닝을 위해서는 하드웨어부터 3D 렌더링, Unity의 구조에 이르기까지 폭넓은 지식이 필요합니다. 
이 장에서는 성능 튜닝을 수행하기 위해 필요한 기초 지식에 대해 정리해 보겠습니다. 

=={basic_hardware} 하드웨어
컴퓨터의 하드웨어는 크게 입력장치, 출력장치, 저장장치, 연산장치, 제어장치의 5가지 장치로 구성됩니다. 
이를 컴퓨터의 5대 장치라고 합니다. 
이 절에서는 이러한 하드웨어 중 성능 튜닝에 있어 중요한 하드웨어에 대한 기초 지식을 정리해 보겠습니다. 

==={basic_hardware_soc} SoC
컴퓨터는 다양한 장치로 구성되어 있습니다. 대표적인 장치로는 제어와 연산을 위한 CPU, 그래픽 연산을 위한 GPU, 음성 및 영상 디지털 데이터를 처리하는 DSP 등을 들 수 있다. 
대부분의 데스크톱 PC 등에서는 이들 장치가 별도의 집적회로로 독립되어 있고, 이를 조합하여 컴퓨터를 구성한다. 
이에 반해 스마트폰에서는 소형화, 저전력화를 위해 이 장치들이 하나의 칩에 구현되어 있습니다. 
이를 System-on-a-chip, 즉 SoC라고 부른다. 

//image[basic_hardware_soc][SoC]

==={basic_hardware_device_soc} 아이폰, 안드로이드와 SoC
스마트폰은 기종에 따라 탑재되는 SoC가 다릅니다. 

예를 들어, 아이폰에는 애플이 설계한 A 시리즈라는 SoC가 사용된다. 
이 시리즈는 A15와 같이 'A'라는 글자와 숫자의 조합으로 명명되며, 버전이 올라갈수록 숫자가 커진다. 

이에 반해 많은 안드로이드에는 Snapdragon이라는 SoC가 사용되고 있다. 
이는 Qualcomm이라는 회사가 제조하는 SoC로, Snapdragon 8 Gen 1이나 Snapdragon 888과 같이 명명된다. 

또한, 아이폰이 애플사에서 제조하는 반면, 안드로이드는 다양한 제조사들이 제조하고 있다. 
따라서 안드로이드에는 아래 @<table>{table_object_soc}에서 볼 수 있듯이 Snapdragon 외에도 다양한 SoC가 존재합니다. 
안드로이드에서 기종에 따른 결함이 발생하기 쉬운 것은 바로 이 때문입니다. 

//table[table_object_soc][안드로이드의 주요 SoC]{
시리즈명	제조사	탑재된 단말기 동향
-------------------- 
Snapdragon	Qualcomm사	다양한 단말기에 사용되고 있다.
Helio	MediaTek	일부 저가형 단말기에 사용됨
Kirin	HiSilicon	화웨이(Huawei)의 단말기
Exynos	삼성	삼성 단말기
//}

성능 튜닝을 할 때, 해당 단말기의 SoC에 무엇이 사용되었고, 어떤 스펙을 가지고 있는지를 파악하는 것이 중요하다. 

//info{
지금까지 Snapdragon의 네이밍은 'Snapdragon'이라는 문자열과 3자리 숫자의 조합이 주를 이루었다. 

이 숫자에는 의미가 있는데, 800번대는 플래그십 모델, 이른바 하이엔드 단말기에 탑재된다. 
여기서부터 숫자가 작아질수록 성능과 가격이 낮아지고, 400번대가 되면 이른바 저가형 단말기가 됩니다. 

400대라도 출시 시기가 빠르면 빠를수록 성능이 향상되기 때문에 일률적으로 말할 수는 없지만, 기본적으로 숫자가 클수록 성능이 높다고 볼 수 있다. 

또한 이 명명 규칙으로는 조만간 숫자가 부족해지기 때문에 2021년부터는 Snapdragon 8 Gen 1과 같은 명칭으로 변경될 것이라고 발표했습니다. 

이러한 네이밍 규칙은 단말기의 성능을 판단하는 지표가 되므로 성능 튜닝을 할 때 기억해두면 도움이 될 것이다. 
//}

==={basic_hardware_cpu} CPU
@<kw>{CPU, Central Processing Unit} 는 컴퓨터의 두뇌라고 할 수 있는 존재로, 프로그램 실행은 물론이고 컴퓨터를 구성하는 다양한 하드웨어와의 연계를 담당하고 있습니다. 
실제로 성능 튜닝을 할 때 CPU 안에서 어떤 처리가 이루어지고 어떤 특성이 있는지를 알면 도움이 되므로 여기서는 성능 관점에서 설명하겠습니다. 

===={basic_hardware_cpu_basic} CPU의 기본

프로그램의 실행 속도를 결정하는 것은 단순한 연산 능력뿐만 아니라 복잡한 프로그램 단계를 얼마나 빠르게 실행할 수 있느냐에 따라 결정됩니다. 
예를 들어 프로그램 중에는 사칙연산도 있지만, 분기 처리도 있습니다. 
CPU로서는 다음에 어떤 명령어가 호출될지 프로그램을 실행하기 전까지는 알 수 없다. 
그래서 CPU는 다양한 명령어를 고속으로 연속적으로 처리할 수 있도록 하드웨어가 설계되어 있습니다. 

//image[basic_cpu_pipeline][CPU의 파이프라인 아키텍처]

CPU 내부에서 명령어가 처리되는 흐름을 파이프라인이라고 하며, 파이프라인 안에서 다음 명령어를 예측하면서 처리되고 있습니다. 
만약 다음 명령어가 예측되지 않으면 파이프라인 스톨이라고 불리는 일시정지가 발생하여 한 번 리셋된다. 
스톨을 일으키는 대부분의 원인은 분기 처리입니다. 분기 자체도 어느 정도 결과를 예측하고 있지만, 그래도 실수할 수 있다. 
내부 구조를 몰라도 성능 튜닝은 가능하지만 
이런 것을 알아두는 것만으로도 코드를 작성할 때 루프 내에서 분기 피하기 등을 의식할 수 있게 됩니다. 

//image[basic_cpu_pipeline_stall][CPU의 파이프라인 스톨]

===={basic_hardware_cpu_compute} CPU의 연산 능력

CPU의 연산 능력은 클럭 주파수(단위는 Hz)와 코어 수로 결정됩니다. 클럭 주파수는 1초당 CPU가 몇 번이나 동작할 수 있는지를 나타낸다. 
따라서 클럭 주파수가 높을수록 프로그램 실행 속도가 빠르다. 

한편 코어 수는 CPU의 병렬 연산 능력에 기여합니다. 코어는 CPU가 동작하는 기본 단위이며, 코어가 여러 개일 경우 멀티코어라고 합니다. 
원래는 싱글 코어만 있었으나, 싱글 코어의 경우 여러 프로그램을 실행시키기 위해 번갈아 가며 실행할 프로그램을 전환하고 있다. 
이를 컨텍스트 스위치라고 하는데, 그 비용이 매우 높습니다. 
스마트폰에 익숙하다면 항상 하나의 앱(프로세스)만이 돌아가고 있다고 생각할 수 있지만, 실제로는 OS 등 다양한 프로세스가 병렬로 작동하고 있습니다. 
그래서 이런 상황에서도 최적의 처리 능력을 제공하기 위해 여러 개의 코어를 탑재한 멀티코어가 대세가 되었다. 
스마트폰용의 경우 2022년 현재 2~8코어 정도가 주류를 이루고 있습니다. 

최근 멀티코어(특히 스마트폰용)는 비대칭 코어(big.LITTLE)를 탑재한 CPU가 주류를 이루고 있다. 
비대칭 코어란 고성능 코어와 저전력 코어를 함께 탑재한 CPU를 말한다. 
비대칭 코어의 장점은 평소에는 저전력 코어만 구동해 배터리 소모를 줄이고, 게임 등 성능을 내야 할 때 코어를 전환해 사용할 수 있다는 점입니다. 
단, 절전 코어만큼 병렬 성능의 최대치가 떨어지므로 코어 수만으로는 판단할 수 없다는 점에 유의해야 합니다. 

//image[basic_cpu_multicore][Snapdragon 8 gen 1의 이기종 코어 구성]

또한 프로그램이 여러 개의 코어를 사용할 수 있는지 여부는 프로그램의 병렬 처리 설명에 따라 달라진다. 
예를 들어 게임 엔진 측에서 물리엔진을 별도의 스레드에서 구동하는 등 효율을 높인 경우와 Unity의 JobSystem 등을 통해 병렬처리를 활용하는 경우도 있지만, 
게임의 메인 루프 자체의 동작은 병렬화할 수 없기 때문에 멀티코어라도 코어 자체의 성능이 높은 것이 유리합니다. 성능이 높은 것이 유리합니다. 

===={basic_hardware_cpu_cache} CPU의 캐시 메모리

CPU와 메인 메모리는 물리적으로 멀리 떨어져 있으며, 접근하는데 약간의 시간(레이턴시)이 필요합니다. 
따라서 프로그램 실행 시 메인 메모리에 저장된 데이터에 접근하려고 할 때, 이 거리가 성능에 큰 병목현상이 발생하게 됩니다. 
그래서 이 레이턴시 문제를 해결하기 위해 CPU 내부에는 캐시 메모리가 탑재되어 있습니다. 
캐시 메모리는 주로 메인 메모리에 저장된 데이터의 일부를 저장하여 프로그램이 필요로 하는 데이터에 빠르게 접근할 수 있도록 한다. 
캐시 메모리에는 L1, L2, L3 캐시가 있는데, 숫자가 작을수록 속도가 빠르지만 용량이 작다. 
얼마나 작은 용량인가 하면, L3 캐시도 2-4MB 수준입니다. 
따라서 CPU 캐시에는 모든 데이터를 저장할 수 없고, 가장 최근에 처리한 데이터만 캐시됩니다. 

//image[basic_cpu_cache][CPU의 L1, L2, L3 캐시와 메인 메모리와의 관계]

따라서 프로그램의 성능을 높이기 위해서는 데이터를 얼마나 효율적으로 캐시에 담을 수 있느냐가 관건인데, 
프로그램 측에서 캐시를 자유롭게 제어할 수 없기 때문에 데이터의 국소성이 중요해집니다. 
게임 엔진에서는 데이터의 국소성을 고려한 메모리 관리가 어렵지만 
유니티의 JobSystem 등 일부 구조에서는 데이터의 국소성을 높인 메모리 배치를 구현할 수 있습니다. 

==={basic_hardware_gpu} GPU
CPU가 프로그램 실행에 특화되어 있는 반면,@<kw>{GPU, Graphics Processing Unit} 는 이미지 처리나 그래픽을 그리는 데 특화된 하드웨어입니다. 


===={basic_hardware_gpu_basic} GPU의 기본
GPU는 그래픽 처리에 특화되어 있기 때문에 CPU와 구조가 크게 다르며, 간단한 계산을 대량으로 병렬로 처리할 수 있도록 설계되어 있다. 
예를 들어 한 장의 이미지를 흑백으로 만들고 싶을 때, CPU로 계산할 경우 어떤 좌표의 RGB 값을 메모리에서 읽어와서 그레이 스케일로 변환하여 다시 메모리에 넣는 과정을 픽셀 단위로 수행해야 합니다. 
이러한 처리는 분기도 없고, 각 픽셀의 계산은 다른 픽셀의 결과에 의존하지 않기 때문에 각 픽셀의 계산을 병렬로 수행하기 쉽다. 

따라서 GPU에서는 대량의 데이터에 대해 동일한 연산을 적용하는 병렬처리를 빠르게 수행할 수 있고, 그 결과 그래픽 처리도 빠르게 수행할 수 있다. 
특히 그래픽 계열에서는 부동소수점 연산이 많이 필요하기 때문에 GPU는 부동소수점 연산을 잘합니다. 
그래서 1초에 몇 번이나 부동소수점 연산을 할 수 있는지를 나타내는 FLOPS라는 성능 지표가 일반적으로 사용된다. 
또한, 연산 능력만으로는 알기 어렵기 때문에 1초당 몇 개의 픽셀을 그릴 수 있는지를 나타내는 필레이트(Fill Rate)라는 지표도 사용됩니다. 

//image[basic_cpu_gpu_difference][CPU와 GPU의 차이점]

===={basic_hardware_gpu_compute} GPU의 연산 능력
GPU의 하드웨어 특징은 정수 및 부동소수점 연산 단위를 포함하는 코어가 대량(수십~수천 개)으로 배치되어 있다는 점이다. 
코어를 많이 배치하기 위해 CPU에서 필요했던 복잡한 프로그램을 실행하는 데 필요한 단위는 필요 없으므로 생략되어 있습니다. 
또한 CPU와 마찬가지로 동작하는 클럭 주파수가 높을수록 초당 많은 연산을 할 수 있습니다. 

===={basic_hardware_gpu_memory} GPU의 메모리
GPU도 당연히 데이터를 처리하기 위해 일시적으로 저장할 수 있는 메모리 영역이 필요합니다. 
보통 이 영역은 메인 메모리와 달리 GPU 전용 메모리가 됩니다. 
따라서 어떤 처리를 하기 위해서는 메인 메모리에서 GPU의 메모리로 데이터를 전송해야 합니다. 
처리 후에는 역순으로 메인 메모리로 되돌려 놓습니다. 
예를 들어 여러 해상도의 큰 텍스처를 전송하는 등 전송량이 많을 경우, 전송에 시간이 걸려 처리의 병목현상이 발생할 수 있으므로 주의해야 합니다. 

//image[basic_gpu_memory][GPU의 메모리 전송]

그러나 모바일에서는 GPU 전용 메모리를 탑재하지 않고 CPU와 GPU가 메인 메모리를 공유하는 아키텍처가 일반적이다. 
이는 GPU의 메모리 용량을 동적으로 변경할 수 있다는 장점이 있는 반면, 전송 대역을 CPU와 GPU가 공유한다는 단점이 있습니다. 
또한 이 경우에도 CPU와 GPU의 메모리 영역 간 데이터 전송이 필요합니다. 

====[column] GPGPU

CPU가 취약했던 대용량 데이터에 대한 병렬 연산을 GPU에서 고속으로 수행할 수 있기 때문에 최근에는 GPU를 그래픽 처리 이외의 목적으로도 적용하는 사례가 있다,@<kw>{GPGPU, General Purpose GPU} 라고 불리고 있습니다. 
특히 AI 등의 머신러닝이나 블록체인 등의 계산 처리에 적용되는 사례가 많아지면서 GPU의 수요가 급증하고, 가격 상승 등의 영향도 나타나고 있습니다. 
유니티에서도 컴퓨트 셰이더라는 기능을 통해 GPGPU를 활용할 수 있습니다. 

====[/column]

==={basic_memory} 메모리
CPU는 그 순간 계산에 필요한 데이터만 가지고 있기 때문에 기본적으로 모든 데이터는 메인 메모리에 저장됩니다. 
물리적인 용량 이상의 메모리를 사용할 수 없기 때문에 너무 많이 사용하면 메모리를 확보할 수 없게 되고, 프로세스가 OS에 의해 강제 종료됩니다. 
일반적으로 이를@<kw>{OOM, Out Of Memory} 로 Kill되었다고 합니다. 
2022년 현재 스마트폰에서는 4-8GB의 메모리 용량을 갖춘 단말기가 대세지만 
그래도 메모리를 너무 많이 사용하지 않도록 주의해야 한다. 

또한 앞서 언급했듯이 메모리가 CPU와 떨어져 있기 때문에 메모리를 의식한 구현을 하느냐 마느냐에 따라 성능 자체도 달라집니다. 
이 절에서는 성능을 고려한 구현을 할 수 있도록 프로그램과 메모리의 관계에 대해 설명합니다. 

===={basic_hardware_memory} 메모리 하드웨어
메인 메모리가 SoC 안에 있는 것이 물리적인 거리상 유리하지만, 메모리는 SoC에 포함되지 않는다. 
이는 SoC 안에 포함되면 메모리 탑재량을 단말기마다 다르게 할 수 없는 등의 이유가 있습니다. 
하지만 메인 메모리가 느리면 프로그램 실행 속도에 큰 영향을 미치기 때문에 상대적으로 빠른 버스로 SoC와 메모리를 연결합니다. 
이 메모리와 버스의 규격으로 스마트폰에서 일반적으로 사용되는 것이 바로@<kw>{LPDDR} 라는 규격입니다. 
LPDDR에도 여러 세대가 있는데, 이론적으로는 수 Gbps 정도의 전송 속도입니다. 
물론 항상 이론상의 성능을 끌어낼 수 있는 것은 아니지만, 게임 개발에서 이 부분이 병목현상이 되는 경우는 거의 없기 때문에 크게 의식할 필요는 없습니다. 

===={basic_memory_os} 메모리와 OS
하나의 OS 안에는 많은 프로세스가 동시에 실행되고 있는데, 크게 시스템 프로세스와 사용자 프로세스가 있습니다. 
시스템계는 OS를 구동하기 위해 중요한 역할을 하는 프로세스가 많고, 서비스로 상주하며 대부분 사용자의 의지와는 무관하게 계속 움직입니다. 
반면 사용자계는 사용자의 의지로 실행되는 프로세스로, OS를 구동하기 위해 필수적인 프로세스는 아니다. 

스마트폰에서 앱의 표시 상태로 포그라운드(전면)와 백그라운드(숨김) 상태가 있는데, 
일반적으로 특정 앱을 포그라운드로 설정하면 다른 앱은 백그라운드가 된다. 
앱이 백그라운드에 있는 동안에도 복귀 처리를 원활하게 하기 위해 프로세스는 일시정지 상태로 존재하며, 메모리도 그대로 유지된다. 
그런데 전체적으로 사용 중인 메모리가 부족해지면 OS에서 정한 우선순위에 따라 프로세스를 Kill한다. 
이때 Kill되기 쉬운 것이 메모리를 많이 사용하는 백그라운드 상태의 사용자계 앱(≒게임)입니다. 
즉, 메모리를 많이 사용하는 게임은 백그라운드로 이동했을 때 Kill될 가능성이 높아지며, 이로 인해 게임으로 돌아와도 다시 시작부터 다시 시작해야 하기 때문에 사용자 체감도가 떨어지게 됩니다. 

만약 메모리를 확보하려고 할 때 다른 킬할 수 있는 프로세스가 없다면 자신이 킬의 대상이 된다. 
또한 iOS와 같이 하나의 프로세스가 물리 용량의 일정 비율 이상의 메모리를 사용할 수 없도록 제어하는 경우도 있습니다. 
따라서 애초에 메모리를 확보할 수 있는 한계라는 것이 존재합니다. 
2022년 현재 주요 RAM이 3GB인 iOS 단말기의 경우 1.3~1.4GB 정도가 한계가 되므로, 게임을 만드는 데 있어서는 이 정도가 한계가 되기 쉽다. 

===={basic_memory_swap} 메모리 스왑
현실에는 다양한 하드웨어의 단말기가 있고, 탑재된 메모리의 물리적 용량이 매우 작은 단말기도 있습니다. 
OS는 그런 단말에서도 최대한 많은 프로세스를 구동하기 위해 다양한 방법으로 가상의 메모리 용량을 확보하려고 합니다. 
그것이 바로 메모리 스왑입니다. 

메모리 스왑에서 사용되는 한 가지 방법이 메모리 압축입니다. 
한동안 접근하지 않는 메모리를 중심으로 압축하여 메모리 상에 저장함으로써 물리적인 용량을 절약합니다. 
다만 압축과 전개 비용이 발생하기 때문에 이용이 활발한 영역이 아닌, 예를 들어 백그라운드에 있는 앱에 대해서만 수행됩니다. 

또 다른 방법은 사용하지 않는 메모리의 저장소 퇴출이다. 
PC와 같이 스토리지가 넉넉한 하드웨어에서는 프로세스를 종료하여 메모리를 확보하는 것이 아니라 
덜 사용되는 메모리를 스토리지로 대피시켜 물리 메모리의 여유 공간을 확보하려는 경우가 있다. 
이는 메모리 압축보다 대용량의 메모리를 확보할 수 있다는 장점이 있지만, 스토리지는 메모리보다 속도가 느리기 때문에 성능상의 제약이 심하고 
애초에 스토리지의 크기가 작은 스마트폰에서는 그다지 현실적이지 않기 때문에 채택되지 않고 있습니다. 

===={basic_stack_heap} 스택과 힙
@<kw>{스택} 과@<kw>{힙} 라는 단어를 한 번쯤은 들어본 적이 있을 것이다. 
스택은 사실 프로그램의 동작과 깊은 관련이 있는 전용 고정 영역입니다. 
함수가 호출되는 타이밍에 인수나 지역변수 등의 분량이 확보되고, 원래의 함수로 돌아갈 때 확보한 분량을 해제하고 반환값을 쌓아 올립니다. 
즉, 함수 안에서 다음 함수를 호출할 때 현재 함수의 정보를 그대로 유지한 채 다음 함수를 메모리에 쌓아갑니다. 
이렇게 함으로써 함수 호출의 구조를 구현하고 있습니다. 
스택 메모리는 아키텍처에 따라 다르지만 1MB로 용량 자체가 매우 적기 때문에 한정된 데이터만 저장합니다. 

//image[basic_stack][스택의 동작 모식도]

반면 힙은 프로그램 내부에서 자유롭게 사용할 수 있는 메모리 영역입니다. 
프로그램이 필요하면 언제든지 메모리 확보 명령어(C에서는 malloc)를 내어 대용량의 데이터를 확보하여 사용할 수 있습니다. 
물론 다 쓰고 나면 해제 처리(free)가 필요합니다. 
C#에서는 메모리 확보와 해제 처리가 런타임에 자동으로 이루어지기 때문에 구현자가 명시적으로 할 필요가 없습니다. 

OS 측에서는 언제 얼마나 많은 메모리 용량이 필요할지 모르기 때문에 필요한 타이밍에 메모리의 여유 공간에서 확보하여 전달합니다. 
메모리를 확보하려고 할 때 연속적으로 그 크기를 확보하지 못하면 메모리 부족이 발생하게 됩니다. 
이 연속이라는 키워드가 중요합니다. 
일반적으로 메모리 확보와 해제를 반복하면,@<kw>{메모리 조각화} 가 발생합니다. 
메모리가 조각화되면 전체 합계로는 여유 공간이 충분해도 연속적으로 비어있는 공간이 없는 경우를 생각할 수 있습니다. 
이런 경우, OS는 우선적으로@<kw>{힙 확장} 을 실행합니다. 
즉, 프로세스에 할당할 메모리를 새로 할당하여 연속적인 영역을 확보합니다. 
하지만 시스템 전체의 메모리는 유한하기 때문에 새로 할당할 메모리가 없어지면 OS에서 프로세스를 Kill하게 됩니다. 

//image[basic_stack_heap][스택과 힙]

스택과 힙을 비교할 때 메모리 확보 성능에 현저한 차이가 발생합니다. 
이는 함수에 필요한 스택의 메모리 양은 컴파일 시점에 확정되기 때문에 메모리 영역이 이미 확보된 반면, 
힙은 실행할 때까지 필요한 메모리 양을 알 수 없기 때문에 매번 빈 공간을 찾아 확보해야 하기 때문이다. 
이것이 힙이 느리고 스택이 빠른 이유입니다. 


====[column] Stack Overflow 에러

Stack Overflow 에러는 함수의 재귀 호출 등으로 스택 메모리를 다 써버렸을 때 발생하는 에러입니다. 
iOS/Android의 기본 스택 크기는 1MB이므로 재귀 호출로 인한 탐색 규모가 커지면 발생하기 쉽습니다. 
일반적으로 재귀 호출을 하지 않거나, 재귀 호출이 깊지 않은 알고리즘으로 변경하는 등의 대책이 가능합니다. 

====[/column]

==={basic_hardware_storage} 스토리지
실제로 튜닝을 진행하다 보면 파일을 불러오는 장면에서 시간이 오래 걸리는 경우가 많다는 것을 알 수 있습니다. 
파일을 불러온다는 것은 파일이 저장되어 있는 스토리지에서 데이터를 읽어들여 프로그램에서 처리할 수 있도록 메모리에 기록하는 것입니다. 그래서 실제로 어떤 일이 일어나는지 알아두면 튜닝할 때 도움이 됩니다. 

먼저 일반적인 하드웨어 아키텍처의 경우, 데이터를 영속화하기 위해 전용 스토리지를 가지고 있다. 
스토리지는 대용량이면서 전원 없이 데이터를 영속화(비휘발성)할 수 있다는 특징이 있습니다. 
이 특징을 활용하여 방대한 자산은 물론, 앱 자체의 프로그램 등도 스토리지에 저장되며, 실행 시점에 스토리지에서 불러와 실행하게 됩니다. 

//image[basic_far_storage][SoC와 스토리지의 관계]


====[column] RAM과 ROM

특히 국내에서는 스마트폰의 메모리를 RAM, 스토리지를 ROM으로 표기하는 것이 일반적이지만, 사실 ROM은 읽기 전용 메모리(Read Only Memory)를 뜻한다. 
이름에서 알 수 있듯이 읽기 전용이고 쓰기가 불가능해야 하는데도 이 용어가 쓰이는 것은 일본의 관습이 강한 것 같습니다. 

====[/column]

그런데 이 스토리지에 대한 읽기/쓰기 처리는 몇 가지 측면에서 프로그램 실행 주기에 비해 매우 느린 편입니다. 

 * CPU와의 물리적 거리가 메모리에 비해 멀기 때문에 레이턴시가 크고 읽기/쓰기 속도가 느리다.
 * 명령된 데이터와 그 주변을 포함하여 블록 단위로 읽어들이기 때문에 낭비가 많다.
 * 순차적 읽기/쓰기는 빠른 반면, 임의적 읽기/쓰기는 느리다.

특히 이 무작위 읽기/쓰기가 느리다는 것은 중요한 포인트입니다. 
애초에 어떤 상황에서 순차적이 되고 어떤 상황에서 랜덤이 되는가 하면, 하나의 파일을 처음부터 순서대로 읽거나 쓰는 경우는 순차적이 되지만 
하나의 파일에서 여러 군데를 건너뛰며 읽거나 쓰는 경우, 또는 여러 개의 작은 파일을 읽거나 쓰는 경우에는 랜덤이 됩니다. 가 됩니다. 
주의할 점은 같은 디렉토리에 있는 여러 개의 파일을 읽고 쓰는 경우에도 물리적으로 연속적으로 배치되어 있는 것은 아니기 때문에 물리적으로 떨어져 있는 경우 랜덤이 됩니다. 

====[column] 스토리지에서 읽기 처리
스토리지에서 파일을 읽어올 때, 자세한 내용은 생략하고 대략 아래와 같은 흐름으로 처리됩니다. 

 1. 프로그램이 스토리지에서 읽으려는 파일의 영역을 스토리지 컨트롤러에 명령
 2. 스토리지 컨트롤러가 1. 명령을 2. 받아 데이터가 있는 물리적으로 읽을 영역을 계산
 3. 데이터를 읽음
데이터를  4. 메모리에 쓰기
 5. 프로그램이 메모리를 통해 데이터에 접근함

하드웨어나 아키텍처에 따라 컨트롤러 등의 레이어가 더 추가되기도 한다. 
정확히 기억할 필요는 없지만, 메모리에서 읽어오는 것에 비해 하드웨어의 처리 과정이 많다는 것을 인지하고 있어야 한다. 

====[/column]

또한 일반적인 스토리지는 하나의 파일을 4KB와 같은 블록 단위로 기록하여 성능과 공간 효율성을 달성하고 있다. 
이 블록은 하나의 파일이라고 해도 물리적으로 연속적으로 배치되어 있는 것은 아니다. 
파일이 물리적으로 분산되어 있는 상태를@<kw>{조각화, 프래그멘테이션} 라고 부르며, 조각화를 해소하는 작업을@<kw>{조각화 제거} 라고 합니다. 
PC의 주류를 이루던 HDD에서는 조각화가 문제가 되는 경우가 많았지만, 플래시 스토리지로 인해 그 영향은 거의 사라졌습니다. 
스마트폰에서는 파일 조각화를 의식할 필요가 없지만, PC를 고려한다면 주의해야 합니다. 

//image[basic_fragmentation][스토리지의 조각화]

====[column] PC와 스마트폰의 스토리지 종류
PC의 세계에서는 HDD와 SSD가 주류인데, HDD를 본 적이 없는 분들도 있겠지만, HDD는 CD처럼 원반 모양으로 기록되는 미디어로, 디스크 위에 헤드가 움직여 자기를 읽어내는 방식이다. 
그래서 구조적으로도 크고, 물리적인 움직임이 발생하기 때문에 지연이 큰 장치였다. 
최근에는 SSD가 보급되었는데, 이는 HDD와 달리 물리적인 움직임이 발생하지 않기 때문에 빠른 성능을 발휘하는 반면, 읽기/쓰기 횟수의 한계(수명)가 있어 자주 읽거나 쓰면 사용할 수 없게 되는 특징이 있다. 
스마트폰은 SSD와 달리 NAND라는 플래시 메모리의 일종인 낸드가 사용된다. 

====[/column]

마지막으로 실제 스마트폰에서 스토리지가 어느 정도의 읽기/쓰기 속도를 가지고 있느냐는 것인데, 2022년 현재 한 가지 기준으로는 읽기 100MB/s 정도입니다. 
예를 들어 10MB의 파일을 읽으려는 경우, 이상적인 상황에서도 파일 전체를 읽는 데 100ms가 필요하다. 
더군다나 여러 개의 작은 파일을 읽어들이는 경우 랜덤 액세스가 발생하기 때문에 점점 더 많은 시간이 소요됩니다. 
이처럼 의외로 파일 로딩에 시간이 오래 걸린다는 것을 항상 염두에 두는 것이 좋다. 
개별 단말기의 구체적인 성능에 대해서는 벤치마크 결과를 모아놓은 사이트( @<fn>{storage_benchmark})가 있으니 참고해 보시기 바랍니다. 

//footnote[storage_benchmark][@<href>{https://maxim-saplin.github.io/cpdt_results/}]

마지막으로 정리하면, 파일 읽기/쓰기가 발생하는 경우 다음과 같은 관점을 의식하는 것이 좋습니다. 

 * 스토리지의 읽기/쓰기 속도는 의외로 느리고, 메모리와 동등한 속도를 기대하지 않는다.
 * 동시에 읽고 쓰는 파일 수를 최대한 줄인다(타이밍을 분산시키거나, 하나의 파일로 묶는 등).

=={basic_graphics} 렌더링
게임에서 렌더링의 처리량은 종종 성능에 부정적인 영향을 미칩니다. 
따라서 렌더링에 대한 지식은 성능 튜닝에 필수적인 요소라고 할 수 있습니다. 
따라서 이 절에서는 렌더링에 대한 기본 지식을 정리해 보겠습니다. 

==={basic_graphics_pipeline} 렌더링 파이프라인
컴퓨터 그래픽스에서는 3D 모델의 버텍스 좌표, 라이트의 좌표와 색상 등의 데이터에 대해 일련의 처리를 거쳐 최종적으로 화면의 각 픽셀에 출력할 색을 출력한다. 
이 처리 과정을@<kw>{렌더링 파이프라인} 이라고 합니다. 

//image[graphics_pipeline_01][렌더링 파이프라인]

렌더링 파이프라인은 CPU에서 GPU로 필요한 데이터를 보내는 것으로 시작된다. 
렌더링할 3D 모델의 버텍스 좌표와 라이트 좌표를 비롯해 오브젝트의 재질 정보, 카메라 정보 등 다양한 데이터가 전송된다. 

이때 전송되는 것은 3D 모델의 버텍스 좌표와 카메라의 좌표, 방향, 화각 등 각각 개별적인 데이터다. 
GPU는 이 정보들을 종합해 '해당 카메라로 해당 물체를 비췄을 때 화면의 어느 위치에 물체가 표시되는지'를 계산해 구한다. 
이 과정을 좌표 변환이라고 합니다. 

객체가 화면의 어느 위치에 표시될지 결정되면, 다음으로 객체의 색을 구해야 합니다. 
이때 GPU는 '그 빛으로 그 재질의 모델을 비췄을 때, 화면의 각 픽셀에 해당하는 부분은 어떤 색이 될 것인가'를 계산해 구한다. 

//image[graphics_pipeline_02][위치와 색상 계산]

위의 처리 중 '화면의 어느 위치에 오브젝트가 표시될 것인가'는@<kw>{버텍스 셰이더} 라는 프로그램에 의해 계산되며, '화면의 각 픽셀에 해당하는 부분은 어떤 색이 될 것인가'는@<kw>{프래그먼트 셰이더} 라는 프로그램에 의해 계산됩니다. 

그리고 이들 셰이더는 자유롭게 작성할 수 있습니다. 
따라서 버텍스 셰이더나 프래그먼트 셰이더에 무거운 처리를 쓰면 처리 부하가 증가한다. 

또한 버텍스 셰이더의 처리는 3D 모델의 버텍스 수만큼 처리되기 때문에 버텍스 수가 많으면 많을수록 처리 부하가 커집니다. 
프래그먼트 셰이더는 렌더링 대상 픽셀 수가 많을수록 처리 부하가 커집니다. 

====[column] 실제 렌더링 파이프라인
실제 렌더링 파이프라인에는 버텍스 셰이더와 프래그먼트 셰이더 외에도 많은 프로세스가 존재하지만, 본 문서에서는 성능 튜닝에 필요한 개념의 이해를 목적으로 하므로 간략하게만 설명합니다. 

====[/column]

==={basic_graphics_overdraw} 반투명 렌더링과 오버드로우
렌더링을 할 때 대상 오브젝트의 투명도는 중요한 문제입니다. 
예를 들어, 지금 카메라에서 봤을 때 일부가 겹치는 두 개의 오브젝트를 생각해보겠습니다. 

//image[graphics_overdraw_01][겹쳐진 두 오브젝트]

먼저 두 오브젝트가 모두 불투명한 경우를 생각해 봅시다. 
이 경우, 카메라에서 봤을 때 앞쪽에 있는 객체부터 순차적으로 그리기 처리를 합니다. 
이렇게 하면 뒤쪽의 오브젝트를 그릴 때 앞쪽의 오브젝트와 겹쳐서 보이지 않는 부분은 처리할 필요가 없습니다. 즉, 이 부분은 프래그먼트 셰이더의 연산을 생략할 수 있어 처리 부하를 최적화할 수 있습니다. 

//image[graphics_overdraw_02][불투명 그리기]

반면, 두 오브젝트가 모두 반투명인 경우, 앞의 오브젝트에 겹쳐진 부분이라도 뒤쪽의 오브젝트가 투명하게 보이지 않으면 부자연스럽다. 이 경우에는 카메라에서 볼 때 안쪽에 있는 오브젝트부터 순차적으로 드로잉 처리를 하고, 겹치는 부분의 색은 이미 드로잉된 색과 블렌딩합니다. 

//image[graphics_overdraw_03][반투명 그리기]

이처럼 반투명 드로잉은 불투명 드로잉과 달리 오브젝트끼리 겹치는 부분에 대해서도 드로잉 처리를 해야 합니다. 
만약 화면 전체에 그려지는 반투명 오브젝트가 두 개 존재한다면, 화면 전체에 대한 처리가 두 번 이루어지게 됩니다. 이렇게 반투명 오브젝트를 겹쳐서 그리는 것을@<kw>{오버드로우} 라고 합니다. 오버드로우가 너무 많으면 GPU에 큰 처리 부하가 발생하여 성능 저하로 이어지기 때문에, 반투명 그리기를 할 때는 적절한 규제가 필요합니다. 

====[column] 포워드 렌더링 가정
렌더링 파이프라인에는 여러 가지 구현 방법이 있습니다. 이 글에서는 포워드 렌더링을 가정하여 설명합니다. 디퍼드 렌더링 등 다른 렌더링 기법에는 부분적으로 적용되지 않는 부분도 있습니다. 

====[/column]

==={basic_graphics_batching} 드로우콜, 세트 패스 콜과 배칭
렌더링은 GPU뿐만 아니라 CPU에도 많은 처리 부하가 발생한다. 

위에서 언급했듯이, 오브젝트를 렌더링할 때 CPU에서 GPU에 그리기 위한 명령을 내린다. 
이를@<kw>{드로우 콜} 라고 하며, 렌더링할 오브젝트 수만큼 실행됩니다. 
이때 텍스처 등의 정보가 이전 드로우콜에서 그린 오브젝트의 텍스처와 다를 경우, 이를 GPU에 설정하는 과정을 거칩니다. 이는@<kw>{세트 패스 콜} 라고 불리며, 비교적 무거운 작업입니다. 이 과정은 CPU의 렌더 스레드에서 이루어지기 때문에 CPU의 처리 부하를 유발하고, 너무 많으면 성능에 영향을 미친다. 

유니티에는 드로우 콜을 줄이기 위해@<kw>{드로우콜 배칭} 라는 메커니즘이 구현되어 있습니다. 
이는 동일한 텍스처 등의 정보, 즉 동일한 머티리얼을 가진 오브젝트의 메시를 CPU 측에서 미리 결합하여 한 번의 드로우 콜로 그리는 방식입니다. 
런타임에 배치하기@<kw>{다이나믹 배칭} 와 미리 결합된 메시를 생성해 두는@<kw>{정적 배치} 가 있습니다. 

또한@<kw>{Scriptable Render Pipeline} 에는@<kw>{SRP Batcher} 라는 메커니즘이 구현되어 있습니다. 
이를 사용하면 셰이더 변형이 동일하다면, 메시나 머티리얼이 다르더라도 세트 패스 호출을 한 번으로 묶을 수 있습니다. 
드로 콜은 줄어들지 않지만, 처리 부하가 큰 것은 세트 패스 콜이기 때문에 이를 줄이기 위한 구조입니다. 

이러한 배칭에 대한 자세한 정보는 @<hd>{tuning_practice_graphics|practice_graphics_draw_call}에서 확인할 수 있습니다. 

====[column] GPU 인스턴싱
배치와 비슷한 효과를 얻을 수 있는 기능입니다,@<kw>{GPU 인스턴싱} 가 있습니다. 
이는 GPU의 기능을 이용해 동일한 메시를 가진 오브젝트를 한 번의 드로우 콜, 세트 패스 콜로 그릴 수 있는 기능입니다. 

====[/column]

=={basic_asset_data} 데이터 표현 방법
게임에는 이미지, 3D 모델, 음성, 애니메이션 등 다양한 데이터가 사용된다. 
이러한 데이터가 어떻게 디지털 데이터로 표현되는지 아는 것은 메모리와 스토리지 용량을 계산하고, 압축 등의 설정을 적절히 하는 데 있어 중요하다. 
이 절에서는 기본적인 데이터 표현 방법에 대해 정리한다. 

==={basic_asset_data_bit} 비트와 바이트
컴퓨터가 표현할 수 있는 가장 작은 단위는 비트입니다. 
1비트는 2진수 1자리로 표현할 수 있는 범위, 즉 0과 1의 두 가지 조합을 표현할 수 있습니다. 
이로는 예를 들어 스위치의 ON/OFF와 같은 간단한 정보만 표현할 수 있습니다. 

//image[basic_asset_data_bit_01][1비트의 정보량]

여기서 2비트를 사용하면 2진수 2자리로 표현할 수 있는 범위, 즉 4종류의 조합을 표현할 수 있음을 알 수 있습니다. 
4종류이므로 예를 들어 위, 아래, 왼쪽, 오른쪽 중 어느 키를 눌렀는지와 같은 정보를 표현할 수 있을 것 같습니다. 

//image[basic_asset_data_bit_02][2비트의 정보량]

마찬가지로 8비트가 되면 2진수 8자리로 표현할 수 있는 범위, 즉 2가지 ^ 8자리 = 256가지입니다. 
여기까지 오면 다양한 정보를 표현할 수 있을 것 같습니다. 
그리고 이 8비트는 1바이트라는 단위로 표현됩니다. 
즉, 1바이트는 256가지의 정보량을 표현할 수 있는 단위라고 할 수 있습니다. 

//image[basic_asset_data_bit_03][8비트의 정보량]

또한 더 큰 숫자를 나타내는 단위로 1000바이트를 나타내는 1킬로바이트(KB)나 1000킬로바이트를 나타내는 1메가바이트(MB)가 존재합니다. 

====[column] 킬로바이트와 키비바이트
위에서는 1KB를 1,000바이트라고 썼지만, 문맥에 따라 1KB를 1,024바이트로 표기하는 경우도 있습니다. 
명시적으로 구분하는 경우에는 1000바이트를 1킬로바이트(KB)라고 부르고, 1,024바이트를 1키비바이트(KiB)라고 부릅니다. 
메가바이트도 마찬가지입니다. 

====[/column]

==={basic_asset_data_texture} 이미지
이미지 데이터는 픽셀의 집합으로 표현됩니다. 
예를 들어 8×8 픽셀의 이미지라면 총 8×8 = 64개의 픽셀로 구성되어 있습니다. 

//image[basic_asset_data_texture_01][이미지 데이터]

이때 각 픽셀은 각각 색상 데이터를 가지고 있습니다. 
그렇다면 색은 디지털 데이터에서 어떻게 표현될까? 

우선 색은 빨강(Red), 초록(Green), 파랑(Blue), 투명도(Alpha)의 4가지 요소를 조합하여 만들어진다. 
이를 채널이라고 부르며, 각 채널의 머리글자를 따서 RGBA라고 표현한다. 

흔히 사용되는 True Color라는 색상 표현 방식에서는 RGBA의 각 값을 각각 256단계로 표현합니다. 
앞 절에서 설명했듯이 256단계는 8비트입니다. 
즉 True Color는 4채널 × 8비트 = 32비트의 정보량으로 표현할 수 있습니다. 

//image[basic_asset_data_texture_02][1색 정보량]

따라서 예를 들어 8×8픽셀의 True Color 이미지라면 그 정보량은 8픽셀 × 8픽셀 × 4채널 × 8비트 = 2,048비트 = 256바이트가 된다. 
1,024×1,024픽셀의 트루컬러 이미지의 정보량은 1,024픽셀×1,024픽셀×4채널×8비트×33,554,432비트×4,194,304바이트×4,096킬로바이트×4메가바이트가 된다. 

==={basic_asset_data_compression} 이미지 압축
실제로 이미지는 대부분 압축된 데이터로 사용된다. 

압축이란 데이터를 저장하는 방법을 고안하여 데이터 용량을 줄이는 것을 말한다. 
예를 들어 지금 같은 색의 픽셀이 5개가 나란히 있다고 가정해보자. 
이 경우 각 픽셀의 색상 정보를 5개씩 가지고 있는 것보다 색상 정보 1개와 그것이 5개가 나란히 있다는 정보를 가지고 있는 것이 정보량을 줄일 수 있습니다. 

//image[basic_asset_data_compression_01][압축]

실제로는 이보다 더 복잡한 압축 방법이 많이 존재한다. 

구체적인 예로 모바일의 대표적인 압축 포맷인 ASTC를 소개합니다. 
ASTC6x6이라는 포맷을 적용하면 1024x1024의 텍스처가 4메가바이트에서 약 0.46메가바이트로 압축된다. 
즉, 용량이 8분의 1 이하로 압축된 결과로 압축의 중요성을 알 수 있습니다. 

참고로 모바일에서 주로 활용되는 ASTC 포맷의 압축률에 대해서는 아래와 같습니다. 

//table[compression][압축 형식과 압축률]{
압축 형식	압축률
-------------------- 
ASTC RGB(A) 4x4	0.25
ASTC RGB(A) 6x6	0.1113
ASTC RGB(A) 8x8	0.1113
ASTC RGB(A) 10x10	0.04
ASTC RGB(A) 12x12	0.0278
//}

참고로 Unity에서는 텍스처 임포트 설정에 따라 플랫폼별로 다양한 압축 방식을 지정할 수 있습니다. 
따라서 비압축 이미지를 임포트하고, 이 임포트 설정에 따라 압축을 적용하여 최종적으로 사용되는 텍스처를 생성하는 방식이 일반적이다. 

====[column] GPU와 압축 형식
어떤 규칙에 따라 압축된 이미지는 당연히 그 규칙에 따라 압축을 풀어야 합니다. 
이 전개 과정은 런타임에 이루어집니다. 
이 처리 부하를 최소화하기 위해서는 GPU가 지원하는 압축 포맷을 사용하는 것이 중요하다. 
모바일 기기의 GPU가 지원하는 대표적인 압축 포맷으로 ASTC를 들 수 있습니다. 

====[/column]

==={basic_asset_data_mesh} 메시
3DCG에서는 3D 공간 위에 수많은 삼각형을 연결하여 입체적인 형상을 표현합니다. 
이 삼각형의 집합을@<kw>{메쉬} 이라고 합니다. 

//image[basic_asset_data_mesh_01][삼각형의 조합에 의한 입체]

이 삼각형은 데이터로서는 3D 공간상의 3점의 좌표 정보로 표현할 수 있습니다. 
이 각 점을@<kw>{정점} 이라고 부르며, 그 좌표를@<kw>{정점 좌표} 이라고 합니다. 
또한 메쉬 하나당 버텍스 정보는 모두 하나의 배열에 저장됩니다. 

//image[basic_asset_data_mesh_02][버텍스 정보]

버텍스 정보는 하나의 배열에 저장되기 때문에, 이 중 어느 것을 조합하여 삼각형을 구성할 것인지에 대한 정보가 별도로 필요합니다. 
이를@<kw>{버텍스 인덱스} 라고 부르며, 버텍스 정보 배열의 인덱스를 나타내는 int 타입의 배열로 표현합니다. 

//image[basic_asset_data_mesh_03][버텍스 인덱스]


오브젝트에 텍스처를 붙이거나 라이팅을 하기 위해서는 더 많은 정보가 필요합니다. 
예를 들어 텍스처를 매핑하려면 UV 좌표가 필요합니다. 
또한 라이팅을 할 때는 버텍스 컬러, 노멀, 접선 등의 정보도 사용됩니다. 

다음 표는 주요 버텍스 정보와 버텍스당 정보량을 정리한 것입니다. 

//table[table_object_vertex_info][버텍스 정보]{
버텍스 이름	버텍스 당 정보량
-------------------- 
버텍스 좌표	3차원 float = 12바이트
UV 좌표	2차원 float = 8바이트
버텍스 컬러	4차원 float = 16바이트
노멀	3차원 float = 12바이트
접선	3차원 float = 12바이트
//}

메시의 데이터는 버텍스의 수와 하나의 버텍스에서 다루는 정보의 양이 많아질수록 커지므로, 버텍스 수와 버텍스 정보의 종류를 미리 정해두는 것이 중요하다. 

==={basic_asset_data_animation} 키프레임 애니메이션
게임에서는 UI의 애니메이션, 3D 모델의 모션 등 많은 부분에서 애니메이션을 사용합니다. 
애니메이션을 구현하는 대표적인 방법으로 키프레임 애니메이션이 있습니다. 

키프레임 애니메이션은 특정 시간(키프레임)의 값을 나타내는 데이터 배열로 구성됩니다. 
키프레임 사이의 값은 보간을 통해 얻어지기 때문에 마치 매끄럽게 연속된 데이터인 것처럼 취급할 수 있습니다. 

//image[basic_asset_data_animation_01][키프레임]

키프레임이 가지고 있는 정보는 시간과 값 외에도 접선과 그 가중치 등이 있다. 
이를 보간 계산에 활용하면 적은 데이터 양으로 더 복잡한 애니메이션을 구현할 수 있습니다. 

//image[basic_asset_data_animation_02][접선과 가중치]

키프레임 애니메이션은 키프레임이 많을수록 복잡한 애니메이션을 표현할 수 있습니다. 
하지만 데이터량도 키프레임의 수에 따라 증가한다. 
이러한 이유로 키프레임 수를 적절히 설정해야 한다. 

최대한 비슷한 곡선을 유지하면서 키프레임을 줄여 데이터량을 압축하는 방법도 있다. 
Unity의 경우 모델 가져오기 설정에서 아래 그림과 같이 키프레임을 줄일 수 있습니다. 

//image[basic_asset_data_animation_03][임포트 설정]

설정 방법에 대한 자세한 내용은 @<hd>{tuning_practice_asset|practice_asset_animation}을 참고하세요. 

=={basic_unity} Unity의 작동 원리

Unity 엔진이 실제로 어떻게 돌아가는지 이해하는 것은 게임을 튜닝하는 데 있어 매우 중요하다. 
이 절에서는 알아야 할 Unity의 작동 원리를 설명합니다. 

==={basic_unity_output_binary} 바이너리와 런타임

먼저 유니티가 실제로 어떤 원리로 런타임을 구동하는지에 대해 설명합니다. 

===={basic_unity_output_binary_csharp} C#과 런타임

유니티로 게임을 만들 때, 개발자는 C#으로 동작을 프로그래밍합니다. 
C#은 컴파일러형 언어이기 때문에 유니티에서 게임을 개발할 때 수시로 컴파일(빌드)이 실행됩니다. 
그런데 C#이 전통적인 C 언어 등과 다른 점은 컴파일하면 기계에서 단독으로 실행되는 기계어가 아니라 
.NET의@<kw>{중간 언어, Intermediate Language; 이후 IL} 로 컴파일된다는 점입니다. 
IL로 변환된 실행 코드는 단독으로 실행할 수 없기 때문에 .NET Framework의 런타임을 이용하여 순차적으로 기계어로 변환하면서 실행됩니다. 

//image[basic_csharp_il][C#의 컴파일 과정]

IL을 끼워 넣는 이유는 일단 기계어로 변환하면 단일 플랫폼에서만 실행할 수 있는 바이너리가 되기 때문이다. 
IL이라면 어떤 플랫폼에서든 해당 플랫폼에 맞는 런타임만 준비하면 동작하게 되므로 
플랫폼마다 바이너리를 준비할 필요가 없어집니다. 
따라서 Unity의 기본 원칙은 소스코드를 컴파일하여 얻은 IL을 그대로 각 환경에 맞는 런타임으로 실행하는 것으로 멀티플랫폼을 구현하고 있습니다. 

====[column] IL 코드를 확인해 보자

평소에는 잘 볼 수 없는 IL 코드는 메모리 확보, 실행 속도 등 성능을 고려하는 데 있어 매우 중요한 부분입니다. 
예를 들어, 배열과 List는 같은 foreach 루프에서도 서로 다른 IL 코드가 출력되며, 배열이 더 성능이 좋은 코드가 됩니다. 
또한 의도하지 않은 숨겨진 힙 할당을 발견할 수도 있습니다. 
이러한 C#과 IL 코드의 대응 감각을 익히기 위해 평소에 자신이 작성한 C# 코드의 IL 변환 결과를 확인해 보는 것을 추천합니다. 
Visual Studio나 Rider와 같은 IDE에서 IL 코드를 열람할 수 있지만, IL 코드 자체는 어셈블리라는 저급 언어이기 때문에 이해하기 어려운 언어입니다. 
그런 경우에는 SharpLab @<fn>{sharplab}이라는 웹 서비스를 이용하면 C# -> IL -> C#과 IL을 역변환한 코드를 확인할 수 있어 이해하기 쉽다. 
이 책의 후반부 @<chapref>{tuning_practice_script_csharp}에서 실제 변환 예제를 소개합니다. 

====[/column]

//footnote[sharplab][@<href>{https://sharplab.io/}]

===={basic_unity_output_binary_il2cpp} IL2CPP

앞서 언급했듯이 유니티는 기본적으로 C#을 IL 코드로 컴파일하여 런타임에 실행하는데, 2015년경부터 일부 환경에서 문제가 발생하기 시작했다. 
바로 iOS나 안드로이드에서 동작하는 앱의 64비트 지원입니다. 
C#은 IL 코드를 실행하기 위해 각각의 환경에서 동작할 수 있는 런타임이 필요한 것은 앞서 언급했듯이 
사실 그전까지의 유니티는 오랜 기간 .NET Framework의 OSS 구현인@<kw>{Mono} 를 포크하여 Unity 자체적으로 수정하여 사용하고 있었습니다. 
즉, Unity가 64bit를 지원하기 위해서는 포크한 Mono를 64bit로 바꿔야 했습니다. 
물론 이는 엄청난 노력이 필요하기 때문에 유니티는 대신@<kw>{IL2CPP} 라는 기술을 개발하여 이 난제를 해결했습니다. 

IL2CPP는 이름 그대로 IL to CPP를 의미하며, IL 코드를 C++ 코드로 변환하는 기술이다. 
C++는 어떤 개발 환경에서도 네이티브 지원되는 범용성이 높은 언어이기 때문에 
C++ 코드로 출력하면 각 개발 툴체인에서 기계어로 컴파일할 수 있다. 
따라서 64bit 대응은 툴체인의 몫이 되므로 Unity 측에서 대응할 필요가 없습니다. 
또한 C#과 달리 빌드 시점에 기계어로 컴파일되기 때문에 런타임에 기계어로 변환할 필요가 없어져 성능이 향상되는 이점도 있습니다. 

C++ 코드는 일반적으로 빌드 시간이 오래 걸린다는 단점이 있지만, 64비트 대응과 성능을 한 번에 해결할 수 있는 IL2CPP라는 기술은 Unity의 핵심이 되었습니다. 

===={basic_unity_output_binary_runtime} Unity 런타임

그런데 유니티에서 개발자는 C#으로 게임을 프로그래밍하지만, 엔진이라고 불리는 유니티 자체의 런타임은 사실 C#으로 구동되는 것은 아닙니다. 
소스 자체는 C++로 작성되며, 플레이어라는 부분은 각 환경에서 실행할 수 있도록 미리 빌드된 상태로 배포된다. 
유니티가 엔진을 C++로 작성하는 이유는 몇 가지 이유가 있을 수 있다. 

 * 빠르고 메모리 절약형 성능을 얻기 위해
 * 최대한 많은 플랫폼에 대응하기 위해
 * 엔진의 지적재산권 보호를 위해(블랙박스화)

개발자가 작성한 C# 코드는 어디까지나 C#으로 동작하기 때문에 Unity에서는 네이티브로 동작하는 엔진 부분과 C# 런타임으로 동작하는 사용자 코드 부분의 두 영역이 필요합니다. 
엔진과 사용자 코드는 실행 중에 적절히 데이터를 주고받으며 동작합니다. 
예를 들어 @<code>{GameObject.transform}를 C#에서 호출하면 
씬의 상태 등 게임 실행 상태는 모두 엔진 내부에서 관리되기 때문에 
먼저 네이티브 호출을 통해 네이티브 영역의 메모리 데이터에 접근하고, 
C#에 값을 반환하는 과정을 거칩니다. 
여기서 주의할 점은 C#과 네이티브는 메모리를 공유하지 않기 때문에 C#에서 필요한 데이터는 매번 C# 측에서 메모리를 확보해야 한다는 점입니다. 
또한 API 호출도 네이티브 호출이 발생하는 등 비용이 많이 들기 때문에 자주 호출하지 않고 값을 캐싱하는 최적화 기법이 필요합니다. 

//image[basic_unity_memory][Unity의 메모리 상태 이미지]

이처럼 Unity를 개발할 때는 눈에 보이지 않는 엔진 부분도 어느 정도 의식해야 합니다. 
따라서 수시로 유니티 엔진의 네이티브 영역과 C#을 연결하는 인터페이스의 소스코드를 살펴보는 것이 좋다. 
다행히 유니티사에서 C# 부분이라면 GitHub에 공개 @<fn>{unity_cs_ref}하고 있기 때문에 대부분 네이티브 호출로 되어 있는 것을 알 수 있는 등 매우 유용합니다. 
필요에 따라 활용하는 것을 추천합니다. 

//footnote[unity_cs_ref][@<href>{https://github.com/Unity-Technologies/UnityCsReference}]

==={basic_unity_output_asset} 애셋의 실체

앞 절에서 설명했듯이 유니티 엔진은 네이티브로 실행되기 때문에 기본적으로 C# 측에서는 데이터를 가지고 있지 않다. 
애셋을 다루는 방식도 마찬가지로 네이티브 영역에서 애셋을 로드하고, C#에 참조를 반환하거나 데이터를 복사하여 반환할 뿐입니다. 
따라서 애셋을 로드할 때는 크게 두 가지로 나눌 수 있는데, 유니티 엔진 측에서 로드하도록 경로를 지정하는 방법과 바이트 배열 등 원시 데이터를 직접 전달하는 방법이 있습니다. 
경로를 지정하는 경우 네이티브 영역에서 로드하기 때문에 C# 측에서 메모리를 소비하지 않지만, 
바이트 배열 등 데이터를 C# 측에서 로드/가공하여 전달하면 C# 측과 네이티브 측에서 이중으로 메모리를 소비하게 됩니다. 

또한, 애셋의 실체가 네이티브 측에 있기 때문에 애셋의 다중 로드나 누수 관련 조사의 난이도도 높아진다. 
이는 개발자가 주로 C# 측의 프로파일링과 디버깅을 중심으로 진행하기 때문이다. 
C# 측의 실행 상태만으로는 이해하기 어렵고, 엔진 측의 실행 상태와 대조하면서 분석해야 하는데, 
네이티브 영역의 프로파일링은 유니티가 제공하는 API에 의존하기 때문에 도구가 제한적이라는 문제가 있다. 
이 책에서 다양한 툴을 활용하여 분석하는 방법을 소개하는데, 이때 C#과 네이티브의 공간을 의식하면 이해가 쉬울 것이다. 

==={basic_unity_thread} 스레드

스레드는 프로그램의 실행 단위이며, 일반적으로 하나의 프로세스 안에 여러 개의 스레드를 생성하면서 처리가 진행됩니다. 
CPU의 하나의 코어는 동시에 하나의 스레드만 처리할 수 있기 때문에 
여러 개의 스레드를 처리하기 위해 빠르게 스레드를 전환하면서 프로그램을 실행합니다. 
이를@<kw>{컨텍스트 스위치} 라고 합니다. 
컨텍스트 스위치를 할 때 오버헤드가 발생하기 때문에 자주 발생하면 처리 효율이 떨어진다. 

//image[basic_thread][스레드 모식도]

프로그램 실행 시 기본이 되는@<kw>{메인 스레드} 가 생성되고, 이 스레드에서 프로그램이 필요에 따라 다른 스레드를 생성하고 관리합니다. 
Unity의 게임 루프는 단일 스레드에서 동작하도록 설계되었기 때문에 
사용자가 작성한 스크립트는 기본적으로 메인 스레드에서 동작하게 됩니다. 
반대로 메인 스레드가 아닌 다른 곳에서 Unity API를 호출하려고 하면 대부분의 API는 오류가 발생한다. 

메인 스레드에서 별도의 스레드를 생성하여 처리를 실행하는 경우, 해당 스레드가 언제 실행되고 언제 완료될지 알 수 없습니다. 
따라서 스레드 간 처리를 동기화하기 위한 수단으로@<kw>{시그널} 라는 메커니즘이 있습니다. 
다른 스레드의 처리를 기다리는 경우, 해당 스레드에서 시그널을 알려주면 대기를 해제할 수 있습니다. 
이 시그널 대기는 Unity 내부에서도 사용되기 때문에 프로파일링 시에도 관찰할 수 있지만, WaitFor~라는 이름에서 알 수 있듯이 단지 다른 처리를 기다리는 것일 뿐이라는 점을 주의해야 합니다. 

==== Unity 내부의 스레드

하지만 모든 처리를 메인 스레드에서 실행하면 프로그램 전체 처리에 시간이 오래 걸리게 됩니다. 
여러 개의 무거운 프로세스가 있고 그것이 상호 의존성이 없는 경우, 어느 정도 처리를 동기화하여 병렬 처리를 할 수 있다면 
프로그램 실행을 단축할 수 있습니다. 
이러한 고속화를 위해 게임 엔진 내부에서는 병렬 처리를 많이 사용합니다. 
그 중 하나가@<kw>{렌더 스레드, Render Thread} 입니다. 
이름 그대로 렌더링 전용 스레드로, 메인 스레드에서 계산한 프레임의 렌더링 정보를 
그래픽 명령어로 GPU에 전송하는 역할을 한다. 

//image[basic_render_thread][메인 스레드와 렌더 스레드]

메인 스레드와 렌더 스레드는 파이프라인처럼 실행되기 때문에 
렌더 스레드가 처리하는 동안 다음 프레임의 계산이 시작된다. 
그런데 만약 렌더 스레드 내에서 한 프레임을 처리하는 시간이 길어지면 
다음 프레임의 렌더링 계산이 끝나도 렌더링을 시작하지 못하고 
메인 스레드는 기다리게 된다. 
게임 개발에서는 메인 스레드, 렌더 스레드 중 어느 한쪽이 무거워지면 FPS가 떨어지므로 주의해야 합니다. 

==== 병렬 처리 가능한 사용자 처리의 스레드화

또한, 게임 특유의 부분으로 물리 엔진이나 흔들림 등 병렬 처리가 가능한 계산 작업들이 많이 존재합니다. 
이러한 계산을 메인 스레드가 아닌 다른 스레드에서 실행할 수 있도록 Unity에서는@<kw>{워커 스레드, Worker Thread} 가 존재합니다. 
Worker Thread는 JobSystem을 통해 생성된 계산 태스크를 실행합니다. 
JobSystem을 이용하여 메인 스레드의 처리 부하를 줄일 수 있다면 적극적으로 활용하도록 합니다. 
물론 JobSystem을 이용하지 않고 자체적으로 스레드를 생성하는 방법도 있습니다. 

스레드는 성능 튜닝에 유용한 반면, 너무 많이 사용하면 오히려 성능이 저하되거나 
처리 복잡도가 높아질 위험도 있으므로 함부로 사용하지 않는 것이 좋습니다. 

==={basic_unity_game_loop} 게임 루프

Unity를 포함한 일반적인 게임 엔진은,@<kw>{게임 루프, 플레이어 루프} 라는 엔진의 루틴 처리가 있습니다. 
루프를 간결하게 표현하면 대략 다음과 같다. 

 1. 키보드, 마우스, 터치 디스플레이 등 컨트롤러의 입력 처리
 2. 1프레임의 시간 동안 진행해야 할 게임 상태 계산
 3. 새로운 게임 상태 렌 더링 
 4. 목표 FPS에 따라 다음 프레임까지 대기

이 루프를 반복하여 게임을 영상으로 GPU에 출력한다. 
만약 1프레임 내 처리에 시간이 오래 걸리게 되면 당연히 FPS가 떨어지게 된다. 

==== Unity의 게임 루프

유니티의 게임 루프는 여러분도 한 번쯤은 보셨을 유니티 공식 레퍼런스에 게임 루프의 도식화 그림 @<fn>{unity_gameloop}이 존재합니다. 

//image[basic_monobehaviour_flowchart][Unity의 이벤트 실행 순서]

이 그림은 엄밀히 말하면 MonoBehaviour의 이벤트 실행 순서를 나타낸 것으로, 게임 엔진으로서의 게임 루프 @<fn>{unity_playerloop}와는 다르지만, 
개발자가 알아야 할 게임 루프로는 이 정도면 충분합니다. 
특히 중요한 이벤트로는 @<code>{Awake, OnEnable, Start, FixedUpdate, Update, LateUpdate, OnDisable, OnDestroy}과 각종 코루틴의 처리 타이밍이 있습니다. 
이벤트의 실행 순서와 타이밍을 잘못 이해하면 예상치 못한 메모리 누수나 불필요한 계산이 발생할 수 있다. 
따라서 중요 이벤트의 호출 타이밍과 해당 이벤트 내에서의 실행 순서 등의 성격을 파악해 두어야 합니다. 

물리 연산은 일반 게임 루프와 같은 간격으로 실행하면 충돌이 판정되지 않고 오브젝트가 빠져나가는 등의 특수한 문제가 있습니다. 
그래서 보통은 물리 연산 루틴의 루프를 고빈도로 돌리도록 게임 루프와 다른 간격으로 루프를 돌립니다. 
하지만 너무 자주 돌리면 메인 게임 루프의 업데이트 처리와 충돌할 수 있기 때문에 어느 정도 동기화해야 한다. 
따라서 물리 연산이 필요 이상으로 무거워지면 프레임의 렌더링 처리에 영향을 미치고, 프레임의 렌더링 처리가 무거워지면 물리 연산이 지연되어 슬립이 발생하는 등 
서로 영향을 미칠 수 있으므로 주의해야 합니다. 

//footnote[unity_gameloop][@<href>{https://docs.unity3d.com/ja/current/Manual/ExecutionOrder.html}]
//footnote[unity_playerloop][@<href>{https://tsubakit1.hateblo.jp/entry/2018/04/17/233000}]

==={basic_unity_gameobject} GameObject
앞서 언급했듯이 Unity의 엔진 자체가 네이티브 방식으로 동작하기 때문에 C#의 Unity API도 대부분 내부 네이티브 API를 호출하기 위한 인터페이스입니다. 
이는 @<code>{GameObject}나 여기에 붙이는 컴포넌트를 정의하는 @<code>{MonoBehaviour}도 마찬가지이며, 항상 C# 측에서 네이티브에 대한 참조를 가지고 있게 됩니다. 
그런데 네이티브 측에서 데이터를 관리하면서 C# 측에서도 해당 참조를 가지고 있으면 폐기 시점에 불편함이 발생한다. 
네이티브 측에서 파기된 데이터에 대해 C#에서 임의로 참조를 지울 수 없기 때문입니다. 

실제로 @<list>{unity_gameobject_destroy_test}에서 파기한 GameObject가 null인지 체크하고 있지만, 로그에는 @<code>{true}이 출력됩니다. 
이는 표준 C#의 동작으로는 부자연스러운데, @<code>{_gameObject}에는 null을 대입하지 않았기 때문에 @<code>{GameObject}타입의 인스턴스에 대한 참조가 남아있어야 합니다. 


//list[unity_gameobject_destroy_test][파기 후 참조 테스트][C#]{
public class DestroyTest : UnityEngine.MonoBehaviour
{
    private UnityEngine.GameObject _gameObject;

    private void Start()
    {
        _gameObject = new UnityEngine.GameObject("test");
        StartCoroutine(DelayedDestroy());
    }

    System.Collections.IEnumerator DelayedDestroy()
    {
        //  cache WaitForSeconds to reuse
        var waitOneSecond = new UnityEngine.WaitForSeconds(1f);
        yield return waitOneSecond;

        Destroy(_gameObject);
        yield return waitOneSecond;

        //  _gameObject is not null, but result is true
        UnityEngine.Debug.Log(_gameObject == null);
    }
}
//}

이는 Unity의 C# 측에서 파기된 데이터에 대한 접근을 제어하고 있기 때문입니다. 
실제로 Unity의 C# 구현부 @<code>{UnityEngine.Object}의 소스 코드 @<fn>{github_unity_object}를 보면 다음과 같이 되어 있습니다. 

//list[unity_object_source][UnityEngine.Object의 == 연산자 구현][C#]{
        //  발췌
        public static bool operator==(Object x, Object y) {
            return CompareBaseObjects(x, y);
        }

        static bool CompareBaseObjects(UnityEngine.Object lhs,
            UnityEngine.Object rhs)
        {
            bool lhsNull = ((object)lhs) == null;
            bool rhsNull = ((object)rhs) == null;

            if (rhsNull && lhsNull) return true;

            if (rhsNull) return !IsNativeObjectAlive(lhs);
            if (lhsNull) return !IsNativeObjectAlive(rhs);

            return lhs.m_InstanceID == rhs.m_InstanceID;
        }

        static bool IsNativeObjectAlive(UnityEngine.Object o)
        {
            if (o.GetCachedPtr() != IntPtr.Zero)
                return true;

            if (o is MonoBehaviour || o is ScriptableObject)
                return false;

            return DoesObjectWithInstanceIDExist(o.GetInstanceID());
        }
//}

요약하면, null 비교를 할 때 네이티브 측의 데이터가 존재하는지 여부를 체크하고 있기 때문에 폐기된 인스턴스에 대한 null 비교가 @<code>{true}가 됩니다. 
이 때문에 null이 아닌 @<code>{GameObject}의 인스턴스가 일부 null인 것처럼 동작한다. 
이 특성은 언뜻 보기에는 편리하지만, 매우 까다로운 측면도 있습니다. 
@<code>{_gameObject} 은 실제로 null이 아니기 때문에 메모리 누수를 유발하기 때문입니다. 
@<code>{_gameObject} 1개 분량의 메모리 누수는 당연하지만, 예를 들어 해당 컴포넌트 중에서 마스터와 같은 거대한 데이터에 대한 참조를 가지고 있는 경우 
C#으로서는 참조가 남아있기 때문에 가비지 컬렉션의 대상이 되지 않기 때문에 엄청난 메모리 누수가 발생하게 됩니다. 
이를 피하기 위해서는 @<code>{_gameObject}에 null을 대입하는 등의 대책이 필요합니다. 

//footnote[github_unity_object][@<href>{https://github.com/Unity-Technologies/UnityCsReference/blob/c84064be69f20dcf21ebe4a7bbc176d48e2f289c/Runtime/Export/Scripting/ UnityEngineObject.bindings.cs}]


==={basic_unity_assetbundle} AssetBundle

스마트폰용 게임은 앱의 크기가 제한되어 있기 때문에 모든 에셋을 앱에 포함시킬 수 없습니다. 
따라서 필요에 따라 애셋을 다운로드하기 위해 Unity에는 AssetBundle이라는 여러 개의 애셋을 묶어 동적으로 로드하는 메커니즘이 있습니다. 
언뜻 보면 쉽게 다룰 수 있을 것 같지만, 대규모 프로젝트의 경우 제대로 설계하지 않으면 예상치 못한 곳에서 메모리를 낭비하는 등 
메모리와 AssetBundle에 대한 충분한 이해와 세심한 설계가 필요합니다. 
따라서 이 절에서는 AssetBundle에 대해 튜닝 관점에서 알아야 할 사항을 설명한다. 

===={basic_unity_assetbundle_compress} AssetBundle의 압축 설정

AssetBundle은 빌드 시 기본적으로 LZMA 압축으로 설정되어 있습니다. 
이를 @<code>{BuildAssetBundleOptions}의 @<code>{UncompressedAssetBundle}으로 바꾸면 무압축으로, 
@<code>{ChunkBasedCompression} 으로 바꾸면 LZ4 압축으로 변경할 수 있습니다. 
이러한 설정의 차이는 아래 @<table>{assetbundle_compression}과 같은 경향을 보입니다. 

//table[assetbundle_compression][AssetBundle의 압축 설정에 따른 차이점]{
항목	무압축	LZMA	LZ4
------------------------------------------------------------- 
파일 크기	특대	특소	소형
로딩 시간	빠른	느림	상당히 빠름
//}

즉, 로딩 시간을 가장 빠르게 하려면 무압축이 좋지만, 파일 크기가 치명적으로 커지기 때문에 스마트폰의 저장 공간 낭비를 피하기 위해서는 기본적으로 사용할 수 없다. 
반면 LZMA는 파일 크기가 가장 작지만 알고리즘 문제로 압축 해제에 시간이 오래 걸리고, 부분 압축 해제 처리가 불가능하다는 단점이 있습니다. 
LZ4는 속도와 파일 크기의 균형 잡힌 압축 설정으로 @<code>{ChunkBasedCompression}이름처럼 부분 압축이 가능하기 때문에 LZMA처럼 전체 압축을 풀지 않고도 부분적으로 불러올 수 있다. 

또한 AssetBundle에는 단말 캐싱 시 압축 설정을 변경하는 @<code>{Caching.compressionEnabled}가 있다. 
즉, 전송은 LZMA로 하고 단말에서 LZ4로 변환하여 다운로드 크기를 최소화하면서 실제 사용 시에는 LZ4의 이점을 누릴 수 있게 됩니다. 
하지만 단말기에서 재압축을 한다는 것은 그만큼 단말기의 CPU 처리 비용이 많이 들고, 메모리와 저장공간을 일시적으로 낭비하게 되는 문제가 있습니다. 

===={basic_unity_assetbundle_dependency} AssetBundle의 종속관계와 중복성

한 애셋이 여러 애셋에 의존하고 있는 경우, AssetBundle화할 때 주의해야 합니다. 
예를 들어 머티리얼 A와 머티리얼 B가 텍스처 C에 의존하는 경우, 텍스처를 AssetBundle화하지 않고 머티리얼 A와 B만 AssetBundle화하면 
생성되는 2개의 AssetBundle 각각에 텍스처 C가 포함되어 중복으로 낭비되는 문제가 발생합니다. 낭비되는 것입니다. 
물론 용량도 낭비지만, 두 머티리얼을 메모리에 로드할 때 텍스처가 따로 인스턴스화되기 때문에 메모리도 낭비하게 됩니다. 

동일한 애셋이 여러 AssetBundle에 포함되는 것을 피하기 위해서는 텍스처 C도 단독으로 AssetBundle화하여 머티리얼의 AssetBundle에서 의존하는 형태로 만들거나 
머티리얼 A, B와 텍스처 C를 하나로 묶은 AssetBundle로 만들어야 합니다. 합니다. 

//image[basic_assetbundle_dependency][AssetBundle 의존관계가 있는 예시입니다.]

===={basic_unity_assetbundle_instance} AssetBundle에서 로드된 애셋의 동일성 확인

AssetBundle에서 애셋을 로드할 때 중요한 특성으로, AssetBundle이 로드되는 동안에는 동일한 애셋을 몇 번을 로드해도 동일한 인스턴스가 반환됩니다. 
이는 Unity 내부에서 이미 로드된 애셋을 관리하고 있음을 나타내며, Unity 내부에서 AssetBundle과 애셋은 묶여 있는 상태가 됩니다. 
이 특성을 이용하면 게임 측에서 애셋의 캐시 메커니즘을 만들지 않고 Unity 측에 맡길 수도 있습니다. 

단, @<code>{AssetBundle.Unload(false)}에서 언로드한 애셋은 @<img>{basic_assetbundle_leak}과 같이 같은 AssetBundle에서 같은 애셋을 다시 로드해도 다른 인스턴스가 되므로 주의해야 합니다. 
이는 언로드하는 시점에 AssetBundle과 애셋의 연결이 해제되어 애셋의 관리가 공중에 떠 있는 상태가 되기 때문입니다. 

//image[basic_assetbundle_leak][AssetBundle과 애셋의 부적절한 관리로 인한 메모리 누수 예시.]

===={basic_unity_assetbundle_destroy} AssetBundle에서 로드한 애셋을 파기하는 경우

@<code>{AssetBundle.Unload(true)} 에서 AssetBundle을 언로드하는 경우, 로드한 애셋도 완전히 파기되기 때문에 메모리와 관련하여 특별히 문제가 없지만, 
@<code>{AssetBundle.Unload(false)} 을 사용하는 경우 적절한 타이밍에 애셋 언로드 명령을 호출하지 않으면 애셋이 파기되지 않습니다. 
따라서 후자를 사용하는 경우 장면 전환 시 등에 적절히 @<code>{Resources.UnloadUnusedAssets}를 호출하여 애셋이 폐기되도록 해야 합니다. 
또한 @<code>{Resources.UnloadUnusedAssets}의 이름에서 알 수 있듯이 참조가 남아있는 경우 해제되지 않는다는 점도 주의해야 합니다. 
참고로 Addressable을 사용하는 경우 내부적으로 @<code>{AssetBundle.Unload(true)}을 호출합니다. 

=={basic_csharp} C# 기초 지식

이 절에서는 성능 튜닝에 필수적인 C#의 언어 사양과 프로그램 실행 시 동작에 대해 설명한다. 

==={basic_csharp_stack_heap} 스택과 힙

@<hd>{basic|basic_stack_heap} 에서는 프로그램 실행 시 메모리 관리 방식으로 스택과 힙이 존재한다는 것을 소개했습니다. 
스택은 OS가 관리하는 반면, 힙은 프로그램 측에서 관리합니다. 
즉, 힙 메모리가 어떻게 관리되는지 알면 메모리를 의식한 구현을 할 수 있습니다. 
힙 메모리 관리 구조는 프로그램을 작성한 소스 코드의 언어 사양에 따라 달라지는 부분이 크기 때문에 C#의 힙 메모리 관리에 대해 설명하겠습니다. 

원래 힙 메모리는 필요한 시점에 메모리를 확보하고, 사용 후에는 메모리를 해제해야 합니다. 
만약 메모리를 해제하지 않으면 메모리 누수가 발생하여 애플리케이션이 사용하는 메모리 영역이 팽창하여 결국에는 크래시가 발생하게 됩니다. 
하지만 C#에는 명시적인 메모리 해제 처리가 없다. 
NET 런타임 환경에서 C# 프로그램이 실행되는 런타임 환경에서는 힙 메모리가 런타임에 의해 자동으로 관리되고, 다 쓴 메모리는 적절한 타이밍에 해제되기 때문이다. 
이 때문에 힙 메모리를@<kw>{매니지드 힙} 이라고도 합니다. 

스택에 확보된 메모리는 함수의 수명과 일치하므로 함수의 마지막에 메모리를 해제해주면 되지만 
힙에 확보된 메모리는 함수의 수명을 넘어 생존하는 경우가 대부분입니다. 
즉, 힙 메모리를 필요로 하는 시점과 사용 종료 시점이 다양하기 때문에 자동적이고 효율적으로 힙 메모리를 사용할 수 있는 메커니즘이 필요합니다. 
자세한 내용은 다음 절에서 소개하겠지만, 그 메커니즘을@<kw>{가비지 컬렉션, Garbage Collection} 라고 부릅니다. 

사실 Unity의@<kw>{GC.Alloc} 은 가비지 컬렉션으로 관리되는 힙 메모리에 할당(Allocation)된 메모리를 나타내는 고유한 용어입니다. 
따라서 GC.Alloc을 줄이면 동적으로 확보되는 힙 메모리의 양을 줄일 수 있습니다. 

==={basic_csharp_gc} 가비지 컬렉션

C#의 메모리 관리에서 사용하지 않는 메모리를 검색하고 해제하는 것을 가비지 컬렉션, 줄여서 'GC'라고 한다. 
가비지 컬렉터는 주기적으로 실행됩니다. 하지만 정확한 실행 시점은 알고리즘에 따라 달라진다. 
이 작업을 통해 힙의 모든 오브젝트를 일제히 조사하고, 이미 참조되지 않는 모든 오브젝트를 삭제한다. 
즉, 참조가 해제된 오브젝트가 삭제되어 메모리 공간을 확보할 수 있습니다. 

가비지 컬렉터에는 다양한 알고리즘이 있지만, 유니티에서는 기본적으로 Boehm GC 알고리즘이 사용된다. 
Boehm GC 알고리즘의 특징은 '비세대적'이고 '비압축형'이라는 점이다. 
'비세대별'이란 가비지 컬렉션을 한 번 실행할 때마다 전체 힙을 한꺼번에 조사해야 한다는 뜻이다. 
이 때문에 힙이 확장될수록 검색 범위가 넓어지기 때문에 성능이 저하된다. 
'비압축형'은 객체 간 간격을 채우기 위해 메모리 내 객체 이동이 이루어지지 않는다는 것을 의미한다. 
즉, 메모리 상에 미세한 틈새를 만드는 파편화가 발생하기 쉽고, 관리 힙이 확장되기 쉬운 경향이 있다. 

각각 계산 비용이 높은 처리이면서 다른 모든 처리를 멈춰버리는 동기식 처리이기 때문에 
게임 중에 실행하면 소위 'Stop the World'라고 불리는 처리 중단 현상이 발생하게 됩니다. 

Unity 2018.3부터는 GCMode를 지정할 수 있게 되어 일시적으로 비활성화할 수 있게 되었습니다. 

//listnum[GCMode][][csharp]{
GarbageCollector.GCMode = GarbageCollector.Mode.Disabled;
//}

하지만 당연히 비활성화된 기간 동안 GC.Alloc을 하게 되면 힙 영역이 확장되고 소모되어 
결국에는 새로 확보할 수 없게 되어 앱 충돌로 이어집니다. 메모리 사용량은 쉽게 증가하기 때문에 
비활성화되어 있는 기간에는 GC.Alloc이 전혀 이루어지지 않도록 구현해야 하며, 
구현 비용도 높아지기 때문에 실제로 사용할 수 있는 장면은 제한적이다. 
(예: 슈팅 게임의 슈팅 파트만 비활성화하는 등) 

또한, Unity 2019부터 Incremental GC를 선택할 수 있게 되었으며, Incremental GC는 
가비지 컬렉션의 처리가 프레임 단위로 이루어지도록 하여 큰 스파이크는 이전보다 완화할 수 있게 되었습니다. 
그러나 프레임당 처리 시간을 줄이면서 최대한의 성능을 발휘해야 하는 게임의 경우, 
굳이 GC.Alloc이 발생하지 않도록 구현해야 합니다. 
구체적인 예는 @<hd>{tuning_practice_script_csharp|practice_script_csharp_sample}에서 확인할 수 있습니다. 

====[column] 언제부터 시작해야 하는가?

게임은 코드 양이 많기 때문에 모든 기능 구현이 완료된 후 성능 튜닝을 진행하다 보면 
종종 GC.Alloc을 피할 수 없는 설계/구현을 만나게 될 수 있습니다. 
설계 초기 단계부터 어디서 발생하는지 항상 염두에 두고 코딩을 하면 
재작업을 통한 비용도 줄일 수 있고, 전체적인 개발 효율이 향상되는 경향이 있습니다. 

이상적인 구현의 흐름은 우선 속도 중심으로 프로토타입을 제작하여 촉감이나 플레이의 핵심이 되는 부분을 검증하고 
그 다음 본 제작 단계로 넘어갈 때 한 번 설계를 검토하고 재구축하는 것이다. 이 재구축하는 단계에서 GC.Alloc의 
박멸에 힘쓰는 것이 건전한 방법일 것이다. 경우에 따라서는 코드의 가독성을 낮춰서라도 속도를 높여야 하는 경우도 있기 때문에 
프로토타입부터 작업하다 보면 개발 속도도 느려질 수 있습니다. 

====[/column]

==={basic_csharp_struct} 구조체(struct)

C#에서 복합형의 정의는 클래스와 구조체가 존재합니다. 기본 전제, 클래스는 참조형, 구조체는 값형입니다. 
MSDN의 'Choosing Between Class and Struct' @<fn>{choosing_class_struct}를 
인용하면서 각각의 특성과 선택 기준, 사용상의 주의점에 대해 알아본다. 

//footnote[choosing_class_struct][@<href>{https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/choosing-between-class-and-struct}]

===={basic_csharp_memory_allocation} 메모리 할당 대상의 차이
참조형과 값형의 첫 번째 차이점은 메모리 할당 대상이 다르다는 점이다. 다소 정확하지는 않지만, 다음과 같이 알아두면 큰 무리가 없다. 
참조형은 메모리의 힙 영역에 할당되어 가비지 컬렉션의 대상이 된다. 
값 유형은 메모리의 스택 영역에 할당되며 가비지 수집 대상이 아니다. 
값형 할당 및 할당 해제 비용은 일반적으로 참조형보다 저렴하다. 

그러나 참조형 필드에 선언된 값형이나 정적 변수는 힙 영역에 할당된다. 
따라서 구조체로 정의한 변수가 반드시 스택 영역에 할당되는 것은 아니라는 점에 유의해야 한다. 

===={basic_csharp_array} 배열 처리
값형 배열은 인라인으로 할당되며, 배열 요소는 값형 실체(인스턴스)가 그대로 나열된다. 
반면 참조형 배열은 배열 요소들이 참조형 실체에 대한 참조(주소)로 정렬된다. 
따라서 값형 배열의 할당과 해제는 참조형에 비해 훨씬 비용이 적게 든다. 
또한 대부분의 경우 값형 배열은 참조의 국소성(공간적 국소성)이 크게 향상되므로 
CPU 캐시 메모리의 적중 확률이 높아져 처리 속도가 빨라진다는 장점이 있습니다. 

===={basic_csharp_value_copy} 값의 복사
참조형 대입(할당)에서는 참조(주소)가 복사됩니다. 반면 값형 대입(할당)은 값 전체가 복사됩니다. 
주소의 크기는 32bit 환경의 경우 4바이트, 64bit 환경의 경우 8바이트이다. 
따라서 큰 참조형 할당은 주소 크기보다 큰 값형 할당보다 비용이 적게 든다. 

또한, 메서드를 이용한 데이터 교환(인수, 반환값)에 있어서도 참조형은 참조(주소)가 값으로 전달되는 반면, 
값형은 인스턴스 자체가 값으로 전달됩니다. 

//listnum[MyStruct_MyClass][][csharp]{
private void HogeMethod(MyStruct myStruct, MyClass myClass){...}
//}

예를 들어 이 메서드에서는 @<code>{MyStruct}의 값 전체가 복사됩니다. 즉, @<code>{MyStruct}의 크기가 커지면 그만큼 복사 비용도 증가합니다. 
반면 @<code>{MyClass}쪽에서는 @<code>{myClass}의 참조가 값으로만 복사되기 때문에 @<code>{MyClass}의 크기가 커져도 
복사 비용은 주소 크기만큼만 발생하기 때문에 일정하게 유지됩니다. 복사 비용의 증가는 처리 부하와 직결되기 때문에 취급하는 데이터 크기에 따라 적절히 선택해야 한다. 

===={basic_csharp_invariant} 불변성
참조형 인스턴스에 가한 변경은 같은 인스턴스를 참조하는 다른 곳에도 영향을 미친다. 
반면, 값형 인스턴스는 값 전달 시 사본이 생성된다. 값형 인스턴스가 변경되면 
당연히 해당 인스턴스의 복사본에는 영향을 미치지 않는다. 복사본은 프로그래머가 명시적으로 생성하는 것이 아니라 
인수가 전달될 때 또는 반환값이 반환될 때 암묵적으로 생성됩니다. 
프로그래머로서 값을 변경한 줄 알았는데, 실제로는 복사본에 값을 설정한 것일 뿐 
목적한 처리와 다른 결과를 초래하는 오류를 한 번쯤은 경험해봤을 것이다. 
변경 가능한 값 유형은 많은 프로그래머에게 혼란을 줄 수 있기 때문에 값 유형은 불변으로 권장되고 있습니다. 

====[column] 참조 전달
흔히 오용하는 것으로 '참조형은 항상 참조 전달이 된다'를 들 수 있는데, 앞서 언급했듯이 참조(주소) 복사가 기본이며 
참조 전달은 ref/in/out 매개변수 수식어를 사용했을 때 이루어집니다. 

//listnum[ref_MyClass][][csharp]{
private void HogeMethod(ref MyClass myClass){...}
//}

참조형 값 전달에서는 참조(주소)를 복사했기 때문에 인스턴스 교체를 해도 복사 원본 인스턴스에는 영향을 주지 않았지만, 
참조 전달을 하면 원본 인스턴스 교체도 가능해집니다. 

//listnum[ref_MyClass_replace][][csharp]{
private void HogeMethod(ref MyClass myClass)
{
    //  인수로 전달된 원래의 인스턴스를 다시 작성하게 됩니다.
    myClass = new MyClass();
}
//}

====[/column]

===={basic_csharp_boxing} 박스화
박스화는 값형에서 @<code>{object}형, 또는 값형에서 인터페이스 형으로 변환하는 과정을 말한다. 
박스는 힙에 할당되어 가비지 컬렉션의 대상이 되는 객체입니다. 
따라서 박싱과 언박싱이 과도하게 이루어지면 GC.Alloc이 발생한다. 이에 반해, 참조형이 캐스트될 때 
이러한 박스화가 이루어지지 않습니다. 

//listnum[simple_boxing][값형에서 object 형으로 캐스팅하면 박스화.][csharp]{
int num = 0;
object obj = num; //  박스화
num = (int) obj;  //  박스화 해제
//}

이렇게 알기 쉽고 무의미한 박스화를 사용하지 않지만, 
메서드에서 사용된다면 어떨까요? 

//listnum[method_boxing][암시적 캐스트로 박스화가 이뤄지는 예시][csharp]{
private void HogeMethod(object data){ ... }

//  중략

int num = 0;
HogeMethod(num); //  인수로 박스화
//}

이런 경우, 무의식적으로 박스화를 하고 있는 경우가 존재합니다. 

간단한 대입에 비해 박스화 및 언박싱은 부하가 큰 과정이다. 
값 타입을 박스화할 때는 새로운 인스턴스를 할당하고 구축해야 한다. 
또한, 박스화만큼은 아니지만 언박싱에 필요한 캐스트도 큰 부하가 발생한다. 

===={basic_csharp_class_or_struct} 클래스와 구조체 선택 기준

 * 구조체를 고려해야 할 조건
 ** 타입의 인스턴스가 적고 유효기간이 짧은 경우가 많은 경우
 ** 다른 객체에 내장되는 경우가 많은 경우

 * 구조체를 피해야 하는 조건: 단, 타입이 다음과 같은 특성을 모두 가지고 있는 경우는 제외한다.
 ** 원시형( @<code>{int}, @<code>{double}등)과 마찬가지로 논리적으로 단일 값을 표현할 때
 ** 인스턴스 크기가 16바이트 미만인 경우
 ** 불변(immutable)이다.
 ** 자주 박스화할 필요가 없다.

위의 선택 조건에 해당하지 않지만, 구조체로 정의된 타입도 다수 존재합니다. 
유니티에서 자주 사용되는 @<code>{Vector4}, @<code>{Quaternion}등 16바이트 미만은 아니지만 구조체로 정의되어 있다. 
이들을 효율적으로 다루는 방법을 확인한 후, 복사 비용이 증가한다면 회피하는 방법을 포함하여 선택하고, 
경우에 따라서는 자체적으로 동등한 기능을 가진 최적화 버전을 만드는 것도 고려해 보시기 바랍니다. 

=={basic_algorithm} 알고리즘과 계산량

게임 프로그래밍에는 다양한 알고리즘이 사용됩니다. 
알고리즘은 어떻게 만들었느냐에 따라 계산 결과는 같지만, 중간 계산 과정이 다르면 성능은 크게 달라질 수 있습니다. 
예를 들어, C#에 표준으로 제공되는 알고리즘이 얼마나 효율적인지, 
당신이 구현한 알고리즘이 얼마나 효율적인지 각각 평가할 수 있는 척도가 필요하게 됩니다. 
이를 측정하는 기준으로 계산량이라는 지표가 사용되고 있습니다. 

=== 계산량이란?
계산량이란 알고리즘의 계산 효율을 측정하는 척도를 말하며, 세분화하면 시간 효율을 측정하는 시간 계산량, 메모리 효율을 측정하는 영역 계산량 등이 있습니다. 
계산량 순서는@<m>{O} 표기법(랜더의 기호)으로 표현됩니다. 컴퓨터 과학이나 수학적 정의 등은 여기서 다룰 내용이 아니므로, 궁금하신 분은 다른 책을 참고하시기 바랍니다. 
또한 본고에서 계산량으로 표기된 것은 시간 계산량으로 취급합니다. 

일반적으로 사용되는 주요 계산량은@<m>{O(1)} 과@<m>{O(n)} 과@<m>{O(n^2)} O(n^2), O(n\log n)@<m>{O(n\log n)} 와 같이 표기된다. 괄호 안의@<m>{n} 은 데이터 수를 나타냅니다. 
어떤 처리가 얼마나 많은 데이터 수에 따라 처리 횟수가 늘어나는지 쉽게 이해할 수 있습니다. 계산량 측면에서 성능을 비교하면 
@<m>{O(1) < O(\log n) < O(n) < O(n\log n) < O(n^2) < O(n^3)} 이 된다. 
@<table>{order_sample}에 데이터 수와 계산 단계 수 비교를, @<img>{basic_order_graph}에 대수로 표시한 비교 그래프를 보여주었다. 
@<m>{O(1)} 은 데이터 수에 의존하지 않기 때문에 비교할 필요도 없이 성능이 더 높기 때문에 제외했습니다. 예를 들어@<m>{O(\log n)} 은 데이터 수가 1만 샘플이더라도 계산 단계 수가 13, 1,000만 샘플이더라도 
계산 단계 수가 23회로 매우 우수한 것을 알 수 있습니다. 

//table[order_sample][주요 계산량에서의 데이터 수와 계산 단계 수]{
@<m>{n}	@<m>{O(\log n)}	@<m>{O(n)}	@<m>{O(n\log n)}	@<m>{O(n^2)}	@<m>{O(n^3)}
O(n^3)	O(n^3)	10	33	100	1,000
100	7	100	664	10,000	1,000,000
1,000,000	10,000	1,000	9,966	1,000,000,000	1,000,000,000,000
10,000	10,000	10,000	132,877	100,000,000,000	1,000,000,000,000,000
//}

//image[basic_order_graph][각 계산량의 대수 표시를 통한 성능 차이 비교]

각 계산량을 보여주기 위해 몇 가지 코드 샘플을 들어보겠습니다. 먼저,@<m>{O(1)} 은 데이터 수에 관계없이 일정한 계산량임을 나타냅니다. 

//listnum[order_1][@<m>{O(1)} 의 코드 예시][csharp]{
private int GetValue(int[] array)
{
    //  array는 어떤 정수값이 들어있는 배열이라고 가정한다.
    var value = array[0];
    return value;
}
//}

이 메서드의 존재 의미는 차치하고, 분명히 array의 데이터 수에 의존하지 않고 일정 횟수(여기서는 1회)로 처리가 끝납니다. 

다음으로@<m>{O(n)} 의 코드 예제를 살펴보자. 

//listnum[order_n][@<m>{O(n)} 의 코드 예시][csharp]{
private bool HasOne(int[] array, int n)
{
    //  array는 length=n이고, 어떤 정수 값이 들어있다고 가정하자.
    for (var i = 0; i < n; ++i)
    {
        var value = array[i];
        if (value == 1)
        {
            return true;
        }
    }
}
//}

이 예제는 정수 값이 들어있는 배열에@<m>{1} 이 존재한다면 @<code>{true}를 반환하는 처리입니다. 우연히 @<code>{array}의 첫 번째에@<m>{1} 이 있다면 가장 빠르게 처리가 끝날 수도 있지만, 
@<code>{array} 어디에도@<m>{1} 가 없는 경우나 @<code>{array}의 마지막에 처음으로@<m>{1} 이 있는 경우 루프는 끝까지 돌아가기 때문에@<m>{n} 번 처리를 하게 된다. 
이 최악의 경우를@<m>{O(n)} 로 나타내며, 데이터 수에 따라 계산량이 늘어나는 것을 알 수 있습니다. 

다음으로@<m>{O(n^2)} 일 때의 예를 살펴보겠습니다. 

//listnum[order_n2][@<m>{O(n^2)} 의 코드 예시][csharp]{
private bool HasSameValue(int[] array1, int[] array2, int n)
{
    //  array1, array2는 length=n이고, 어떤 정수 값이 들어있다고 가정한다.
    for (var i = 0; i < n; ++i)
    {
        var value1 = array1[i];
        for (var j = 0; j < n; ++j)
        {
            var value2 = array2[j];
            if (value1 == value2)
            {
                return true;
            }
        }
    }

    return false;
}
//}

이 메서드는 이중 루프를 통해 두 배열의 어딘가에 같은 값이 포함되어 있으면 @<code>{true}을 반환하는 메서드입니다. 
최악의 경우를 생각해보면 모두 불일치하는 경우이므로, 이 경우에는@<m>{n^2} 번 처리하게 됩니다. 

//info{
여담이지만, 계산량 개념에서는 최대 차수의 항으로만 표현합니다. 위 예제의 3가지 메소드를 1회씩 실행하는 메소드를 만들면 
최대 차수의@<m>{O(n^2)} 이 됩니다. (O(n^2)@<m>{O(n^2+n+1)} 가 되지 않습니다) 

또한, 계산량은 데이터 수가 충분히 많을 때를 기준으로 한 것이며, 실제 측정 시간과 반드시 연동되는 것은 아니라는 점에 유의해야 합니다. 
@<m>{O(n^5)} 와 같이 엄청난 계산량으로 보이지만 데이터 수가 적으면 문제가 되지 않는 경우도 있기 때문에 
계산량은 참고하되, 매번 데이터 수를 고려하여 문제 없는 처리시간에 맞는지 측정하는 것을 권장합니다. 

//}

=== 기본적인 컬렉션과 데이터 구조
C#에는 다양한 데이터 구조를 가진 컬렉션 클래스가 준비되어 있습니다. 
자주 사용하는 것을 예로 들면서 주요 메소드의 계산량을 기준으로 각각 어떤 상황에서 어떤 메소드를 사용해야 하는지 소개합니다. 

여기서 소개하는 컬렉션 클래스의 메소드 계산량은 MSDN에 모두 공개되어 있으므로 
최적의 컬렉션 클래스를 선정할 때 확인하면 더욱 안전할 것이다. 

==== List<T>
가장 많이 사용되는 @<code>{List<T>}입니다. 데이터 구조는 배열입니다. 
데이터의 정렬 순서가 중요하거나, 인덱스를 통한 데이터 조회 및 업데이트가 많은 경우에 사용하면 효과적입니다. 
반대로 요소의 삽입이나 삭제가 많은 경우에는 조작한 인덱스 이후의 복사본이 필요하고 계산량이 많아지므로 
@<code>{List<T>} 의 사용은 피하는 것이 좋습니다. 

또한, Add로 용량을 초과하려고 하면 배열의 확보된 메모리 확장이 이루어집니다. 
메모리 확장 시에는 현재 Capacity의 2배를 확보하게 되므로 Add를@<m>{O(1)} 로 사용하기 위해서도 
확장을 발생시키지 않고 사용할 수 있도록 적절한 초기값을 설정하여 사용해야 한다. 

//table[collection_list][List<T>]{
메서드	계산량
---------------------------- 
Add	@<m>{O(1)} 단, 용량을 초과하면@<m>{O(n)}
Insert	@<m>{O(n)}
IndexOf/Contains	@<m>{O(n)}
RemoveAt	@<m>{O(n)}
Sort	@<m>{O(n\log n)}
//}

==== LinkedList<T>
@<code>{LinkedList<T>} 의 데이터 구조는 연결 목록입니다. 연결 리스트는 기본적인 데이터 구조로 각 노드가 다음 노드에 대한 참조를 가지고 있는 것과 같은 이미지입니다. 
C#의 @<code>{LinkedList<T>}은 양방향 연결 리스트이므로 앞뒤 노드에 대한 참조를 각각 가지고 있습니다. @<code>{LinkedList<T>}은 요소의 추가와 삭제에 강한 특징을 가지고 있지만 
배열 내의 특정 요소에 접근하는 것은 취약합니다. 자주 추가나 삭제를 해야 하는 것처럼 일시적으로 데이터를 보관하는 처리를 만들고 싶을 때 등에 적합합니다. 

//table[collection_linkedlist][LinkedList<T]{
메서드	계산량
---------------------------- 
AddFirst/AddLast	@<m>{O(1)}
AddAfter/AddBefore	@<m>{O(1)}
Remove/RemoveFirst/RemoveLast	@<m>{O(1)}
Contains	@<m>{O(n)}
//}

==== Queue<T>
@<code>{Queue<T>} 은 선입선출법: FIFO(First in first out)를 구현한 컬렉션 클래스입니다. 
입력 조작 등을 관리할 때 등 이른바 대기열을 구현할 때 사용됩니다. 
@<code>{Queue<T>} 에서는 순환 배열을 사용하고 있습니다. @<code>{Enqueue}에서 요소를 맨 뒤에 추가하고, @<code>{Dequeue}에서 맨 앞의 요소를 꺼내면서 삭제합니다. 
용량을 초과하여 추가할 때는 확장이 이루어집니다. @<code>{Peek}는 삭제하지 않고 맨 앞의 요소를 꺼내는 작업입니다. 계산량을 보면 알 수 있듯이 
@<code>{Enqueue} 과 @<code>{Dequeue}에만 사용하면 
높은 성능을 얻을 수 있지만 탐색 등의 작업에는 적합하지 않을 것입니다. @<code>{TrimExcess}는 용량을 줄이는 방법이지만 
성능 튜닝 관점에서 보면 애초에 용량이 증감하지 않도록 사용하면 @<code>{Queue<T>}의 강점을 더욱 살릴 수 있습니다. 

//table[collection_queue][Queue<T]{
메서드	계산량
---------------------------- 
Enqueue	@<m>{O(1)} 단, 용량을 초과하면@<m>{O(n)}
Dequeue	@<m>{O(1)}
Peek	@<m>{O(1)}
Contains	@<m>{O(n)}
TrimExcess	@<m>{O(n)}
//}

==== Stack<T>
@<code>{Stack<T>} 은 후입선출법: LIFO(Last in first out)를 구현한 컬렉션 클래스입니다. 
@<code>{Stack<T>} 은 배열로 구현되어 있습니다. @<code>{Push}에서 맨 앞에 요소를 추가하고, @<code>{Pop}에서 맨 앞의 요소를 꺼내면서 삭제합니다. 
@<code>{Peek} 은 삭제하지 않고 맨 앞의 요소를 꺼내는 작업입니다. 
자주 사용되는 장면으로는 화면 전환을 구현할 때 전환 시 진행했던 장면 정보를 @<code>{Push}로 남겨두고, 뒤로 가기 버튼을 눌렀을 때 @<code>{Pop}하는 경우 등을 들 수 있습니다. 
@<code>{Stack} 도 @<code>{Queue}과 마찬가지로 @<code>{Push}과 @<code>{Pop}만을 사용하면 높은 성능을 얻을 수 있습니다. 요소 탐색 등은 하지 않고, 용량의 증감에도 신경을 써야 한다. 

//table[collection_stack][Stack<T>]{
메서드	계산량
---------------------------- 
Push	@<m>{O(1)} 단, 용량을 초과하면@<m>{O(n)}
Pop	@<m>{O(1)}
Peek	@<m>{O(1)}
Contains	@<m>{O(n)}
TrimExcess	@<m>{O(n)}
//}

==== Dictionary<TKey, TValue
지금까지 소개한 컬렉션은 순서에 의미를 부여하는 컬렉션이었지만, @<code>{Dictionary<TKey, TValue>}은 인덱싱에 특화된 컬렉션 클래스입니다. 
데이터 구조는 해시 테이블(연관 배열의 일종)로 구현되어 있다. 키에 해당하는 값이 있는 사전(사전의 경우 단어가 키, 설명이 값)과 같은 구조입니다. 
@<code>{Dictionary<TKey, TValue>} 은 메모리를 많이 소모하는 단점이 있지만, 그 대신 참조 속도가@<m>{O(1)} 로 빠르다. 
열거나 탐색을 필요로 하지 않고 값을 참조하는 것에 중점을 두는 경우에 매우 유용합니다. 또한, 용량을 미리 설정해 두는 것이 좋습니다. 

//table[collection_dictionary][Dictionary<TKey, TValue]{
메서드	계산량
---------------------------- 
Add	@<m>{O(1)} 단, 용량을 초과하면@<m>{O(n)}
TryGetValue	@<m>{O(1)}
Remove	@<m>{O(1)}
ContainsKey	@<m>{O(1)}
ContainsValue	@<m>{O(n)}
//}

=== 계산량을 낮추기 위한 노력
지금까지 소개한 컬렉션 외에도 다양한 컬렉션이 준비되어 있습니다. 
물론 @<code>{List<T>}(배열)만으로도 비슷한 처리를 구현할 수 있지만, 
보다 적합한 컬렉션 클래스를 선택하면 계산량을 최적화할 수 있습니다. 
계산량을 고려하여 메소드를 구현하는 것만으로도 무거운 처리를 피할 수 있을 것입니다. 
코드 최적화의 한 가지 방법으로 자신이 만든 메소드의 계산량을 확인하여 
보다 적은 계산량으로 만들 수 있는지 검토해보는 것은 어떨까요? 

====[column] 고안 방법: 메모화
어떤 복잡한 계산을 해야 하는 매우 높은 계산량의 메소드( @<code>{ComplexMethod})가 있다고 가정해 봅시다. 
하지만 어떻게 해도 계산량을 줄일 수 없을 때도 있을 것입니다. 
이럴 때 사용되는 수단으로 메모화라는 방법이 있습니다. 

여기서 @<code>{ComplexMethod}은 인수를 주면 그에 대응하는 결과를 고유하게 반환한다고 가정합니다. 
먼저 전달된 인수가 처음 전달될 때는 복잡한 과정을 거칩니다. 계산 후 인자와 계산 결과를 @<code>{Dictionary<TKey, TValue>}에 넣어 캐싱해 둡니다. 
두 번째부터는 먼저 캐싱이 되어 있지 않은지 확인하고, 이미 캐싱이 되어 있다면 그 결과만 반환하고 종료합니다. 
이렇게 하면 첫 번째가 아무리 계산량이 많아도 두 번째 이후부터는@<m>{O(1)} 로 낮출 수 있습니다. 
만약 미리 전달될 수 있는 인수가 어느 정도 정해져 있다면, 게임 전에 계산을 미리 해놓고 캐싱을 해두면 
사실상@<m>{O(1)} 의 계산량으로 처리할 수 있다. 

====[/column]
